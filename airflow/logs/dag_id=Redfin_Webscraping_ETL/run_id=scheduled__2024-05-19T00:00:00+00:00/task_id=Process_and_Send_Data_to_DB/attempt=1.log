[2024-05-20T00:00:04.430+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-20T00:00:04.465+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Redfin_Webscraping_ETL.Process_and_Send_Data_to_DB scheduled__2024-05-19T00:00:00+00:00 [queued]>
[2024-05-20T00:00:04.475+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Redfin_Webscraping_ETL.Process_and_Send_Data_to_DB scheduled__2024-05-19T00:00:00+00:00 [queued]>
[2024-05-20T00:00:04.475+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 6
[2024-05-20T00:00:04.493+0000] {taskinstance.py:2330} INFO - Executing <Task(SparkSubmitOperator): Process_and_Send_Data_to_DB> on 2024-05-19 00:00:00+00:00
[2024-05-20T00:00:04.502+0000] {standard_task_runner.py:63} INFO - Started process 12941 to run task
[2024-05-20T00:00:04.520+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Redfin_Webscraping_ETL', 'Process_and_Send_Data_to_DB', 'scheduled__2024-05-19T00:00:00+00:00', '--job-id', '463', '--raw', '--subdir', 'DAGS_FOLDER/webscrapping.py', '--cfg-path', '/tmp/tmpcv154h8z']
[2024-05-20T00:00:04.535+0000] {standard_task_runner.py:91} INFO - Job 463: Subtask Process_and_Send_Data_to_DB
[2024-05-20T00:00:04.697+0000] {task_command.py:426} INFO - Running <TaskInstance: Redfin_Webscraping_ETL.Process_and_Send_Data_to_DB scheduled__2024-05-19T00:00:00+00:00 [running]> on host eddd84e36bad
[2024-05-20T00:00:04.847+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='svc' AIRFLOW_CTX_DAG_ID='Redfin_Webscraping_ETL' AIRFLOW_CTX_TASK_ID='Process_and_Send_Data_to_DB' AIRFLOW_CTX_EXECUTION_DATE='2024-05-19T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-19T00:00:00+00:00'
[2024-05-20T00:00:04.848+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-20T00:00:04.903+0000] {base.py:84} INFO - Using connection ID 'spark_default' for task execution.
[2024-05-20T00:00:04.904+0000] {spark_submit.py:401} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,com.datastax.spark:spark-cassandra-connector_2.12:3.5.0,org.apache.kafka:kafka-clients:3.5.1,commons-logging:commons-logging:1.2 --name arrow-spark --deploy-mode client dags/includes/jobs/spark_consumer.py
[2024-05-20T00:00:05.407+0000] {spark_submit.py:571} INFO - /home/***/.local/lib/python3.11/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found
[2024-05-20T00:00:08.744+0000] {spark_submit.py:571} INFO - :: loading settings :: url = jar:file:/home/***/.local/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2024-05-20T00:00:08.908+0000] {spark_submit.py:571} INFO - Ivy Default Cache set to: /home/***/.ivy2/cache
[2024-05-20T00:00:08.909+0000] {spark_submit.py:571} INFO - The jars for the packages stored in: /home/***/.ivy2/jars
[2024-05-20T00:00:08.912+0000] {spark_submit.py:571} INFO - org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
[2024-05-20T00:00:08.913+0000] {spark_submit.py:571} INFO - com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency
[2024-05-20T00:00:08.913+0000] {spark_submit.py:571} INFO - org.apache.kafka#kafka-clients added as a dependency
[2024-05-20T00:00:08.913+0000] {spark_submit.py:571} INFO - commons-logging#commons-logging added as a dependency
[2024-05-20T00:00:08.913+0000] {spark_submit.py:571} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-04815773-d12d-467b-b825-3aedc9f7796c;1.0
[2024-05-20T00:00:08.913+0000] {spark_submit.py:571} INFO - confs: [default]
[2024-05-20T00:00:09.081+0000] {spark_submit.py:571} INFO - found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 in central
[2024-05-20T00:00:09.124+0000] {spark_submit.py:571} INFO - found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 in central
[2024-05-20T00:00:09.160+0000] {spark_submit.py:571} INFO - found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
[2024-05-20T00:00:09.198+0000] {spark_submit.py:571} INFO - found org.apache.hadoop#hadoop-client-api;3.3.4 in central
[2024-05-20T00:00:09.211+0000] {spark_submit.py:571} INFO - found org.xerial.snappy#snappy-java;1.1.10.3 in central
[2024-05-20T00:00:09.222+0000] {spark_submit.py:571} INFO - found org.slf4j#slf4j-api;2.0.7 in central
[2024-05-20T00:00:09.236+0000] {spark_submit.py:571} INFO - found com.google.code.findbugs#jsr305;3.0.0 in central
[2024-05-20T00:00:09.246+0000] {spark_submit.py:571} INFO - found org.apache.commons#commons-pool2;2.11.1 in central
[2024-05-20T00:00:09.256+0000] {spark_submit.py:571} INFO - found com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 in central
[2024-05-20T00:00:09.263+0000] {spark_submit.py:571} INFO - found com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 in central
[2024-05-20T00:00:09.271+0000] {spark_submit.py:571} INFO - found org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central
[2024-05-20T00:00:09.280+0000] {spark_submit.py:571} INFO - found com.datastax.oss#java-driver-core-shaded;4.13.0 in central
[2024-05-20T00:00:09.347+0000] {spark_submit.py:571} INFO - found com.datastax.oss#native-protocol;1.5.0 in central
[2024-05-20T00:00:09.371+0000] {spark_submit.py:571} INFO - found com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central
[2024-05-20T00:00:09.394+0000] {spark_submit.py:571} INFO - found com.typesafe#config;1.4.1 in central
[2024-05-20T00:00:09.442+0000] {spark_submit.py:571} INFO - found io.dropwizard.metrics#metrics-core;4.1.18 in central
[2024-05-20T00:00:09.475+0000] {spark_submit.py:571} INFO - found org.hdrhistogram#HdrHistogram;2.1.12 in central
[2024-05-20T00:00:09.483+0000] {spark_submit.py:571} INFO - found org.reactivestreams#reactive-streams;1.0.3 in central
[2024-05-20T00:00:09.497+0000] {spark_submit.py:571} INFO - found com.github.stephenc.jcip#jcip-annotations;1.0-1 in central
[2024-05-20T00:00:09.517+0000] {spark_submit.py:571} INFO - found com.github.spotbugs#spotbugs-annotations;3.1.12 in central
[2024-05-20T00:00:09.571+0000] {spark_submit.py:571} INFO - found com.google.code.findbugs#jsr305;3.0.2 in central
[2024-05-20T00:00:09.629+0000] {spark_submit.py:571} INFO - found com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central
[2024-05-20T00:00:09.680+0000] {spark_submit.py:571} INFO - found com.datastax.oss#java-driver-query-builder;4.13.0 in central
[2024-05-20T00:00:09.723+0000] {spark_submit.py:571} INFO - found org.apache.commons#commons-lang3;3.10 in central
[2024-05-20T00:00:09.741+0000] {spark_submit.py:571} INFO - found com.thoughtworks.paranamer#paranamer;2.8 in central
[2024-05-20T00:00:09.769+0000] {spark_submit.py:571} INFO - found org.scala-lang#scala-reflect;2.12.11 in central
[2024-05-20T00:00:09.795+0000] {spark_submit.py:571} INFO - found org.apache.kafka#kafka-clients;3.5.1 in central
[2024-05-20T00:00:09.809+0000] {spark_submit.py:571} INFO - found com.github.luben#zstd-jni;1.5.5-1 in spark-list
[2024-05-20T00:00:09.820+0000] {spark_submit.py:571} INFO - found org.lz4#lz4-java;1.8.0 in central
[2024-05-20T00:00:09.836+0000] {spark_submit.py:571} INFO - found commons-logging#commons-logging;1.2 in central
[2024-05-20T00:00:09.926+0000] {spark_submit.py:571} INFO - :: resolution report :: resolve 964ms :: artifacts dl 49ms
[2024-05-20T00:00:09.927+0000] {spark_submit.py:571} INFO - :: modules in use:
[2024-05-20T00:00:09.927+0000] {spark_submit.py:571} INFO - com.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]
[2024-05-20T00:00:09.928+0000] {spark_submit.py:571} INFO - com.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]
[2024-05-20T00:00:09.929+0000] {spark_submit.py:571} INFO - com.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]
[2024-05-20T00:00:09.929+0000] {spark_submit.py:571} INFO - com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]
[2024-05-20T00:00:09.930+0000] {spark_submit.py:571} INFO - com.datastax.oss#native-protocol;1.5.0 from central in [default]
[2024-05-20T00:00:09.930+0000] {spark_submit.py:571} INFO - com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 from central in [default]
[2024-05-20T00:00:09.931+0000] {spark_submit.py:571} INFO - com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 from central in [default]
[2024-05-20T00:00:09.932+0000] {spark_submit.py:571} INFO - com.github.luben#zstd-jni;1.5.5-1 from spark-list in [default]
[2024-05-20T00:00:09.932+0000] {spark_submit.py:571} INFO - com.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]
[2024-05-20T00:00:09.933+0000] {spark_submit.py:571} INFO - com.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]
[2024-05-20T00:00:09.934+0000] {spark_submit.py:571} INFO - com.google.code.findbugs#jsr305;3.0.2 from central in [default]
[2024-05-20T00:00:09.934+0000] {spark_submit.py:571} INFO - com.thoughtworks.paranamer#paranamer;2.8 from central in [default]
[2024-05-20T00:00:09.935+0000] {spark_submit.py:571} INFO - com.typesafe#config;1.4.1 from central in [default]
[2024-05-20T00:00:09.935+0000] {spark_submit.py:571} INFO - commons-logging#commons-logging;1.2 from central in [default]
[2024-05-20T00:00:09.935+0000] {spark_submit.py:571} INFO - io.dropwizard.metrics#metrics-core;4.1.18 from central in [default]
[2024-05-20T00:00:09.936+0000] {spark_submit.py:571} INFO - org.apache.commons#commons-lang3;3.10 from central in [default]
[2024-05-20T00:00:09.936+0000] {spark_submit.py:571} INFO - org.apache.commons#commons-pool2;2.11.1 from central in [default]
[2024-05-20T00:00:09.937+0000] {spark_submit.py:571} INFO - org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
[2024-05-20T00:00:09.938+0000] {spark_submit.py:571} INFO - org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
[2024-05-20T00:00:09.939+0000] {spark_submit.py:571} INFO - org.apache.kafka#kafka-clients;3.5.1 from central in [default]
[2024-05-20T00:00:09.939+0000] {spark_submit.py:571} INFO - org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 from central in [default]
[2024-05-20T00:00:09.940+0000] {spark_submit.py:571} INFO - org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 from central in [default]
[2024-05-20T00:00:09.940+0000] {spark_submit.py:571} INFO - org.hdrhistogram#HdrHistogram;2.1.12 from central in [default]
[2024-05-20T00:00:09.941+0000] {spark_submit.py:571} INFO - org.lz4#lz4-java;1.8.0 from central in [default]
[2024-05-20T00:00:09.941+0000] {spark_submit.py:571} INFO - org.reactivestreams#reactive-streams;1.0.3 from central in [default]
[2024-05-20T00:00:09.941+0000] {spark_submit.py:571} INFO - org.scala-lang#scala-reflect;2.12.11 from central in [default]
[2024-05-20T00:00:09.942+0000] {spark_submit.py:571} INFO - org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]
[2024-05-20T00:00:09.942+0000] {spark_submit.py:571} INFO - org.slf4j#slf4j-api;2.0.7 from central in [default]
[2024-05-20T00:00:09.943+0000] {spark_submit.py:571} INFO - org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
[2024-05-20T00:00:09.944+0000] {spark_submit.py:571} INFO - :: evicted modules:
[2024-05-20T00:00:09.944+0000] {spark_submit.py:571} INFO - org.apache.kafka#kafka-clients;3.4.1 by [org.apache.kafka#kafka-clients;3.5.1] in [default]
[2024-05-20T00:00:09.945+0000] {spark_submit.py:571} INFO - commons-logging#commons-logging;1.1.3 by [commons-logging#commons-logging;1.2] in [default]
[2024-05-20T00:00:09.945+0000] {spark_submit.py:571} INFO - com.google.code.findbugs#jsr305;3.0.0 by [com.google.code.findbugs#jsr305;3.0.2] in [default]
[2024-05-20T00:00:09.945+0000] {spark_submit.py:571} INFO - org.slf4j#slf4j-api;1.7.26 by [org.slf4j#slf4j-api;2.0.7] in [default]
[2024-05-20T00:00:09.946+0000] {spark_submit.py:571} INFO - org.xerial.snappy#snappy-java;1.1.10.1 by [org.xerial.snappy#snappy-java;1.1.10.3] in [default]
[2024-05-20T00:00:09.946+0000] {spark_submit.py:571} INFO - org.slf4j#slf4j-api;1.7.36 by [org.slf4j#slf4j-api;2.0.7] in [default]
[2024-05-20T00:00:09.946+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2024-05-20T00:00:09.947+0000] {spark_submit.py:571} INFO - |                  |            modules            ||   artifacts   |
[2024-05-20T00:00:09.947+0000] {spark_submit.py:571} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2024-05-20T00:00:09.947+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2024-05-20T00:00:09.947+0000] {spark_submit.py:571} INFO - |      default     |   35  |   0   |   0   |   6   ||   29  |   0   |
[2024-05-20T00:00:09.948+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2024-05-20T00:00:09.948+0000] {spark_submit.py:571} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-04815773-d12d-467b-b825-3aedc9f7796c
[2024-05-20T00:00:09.948+0000] {spark_submit.py:571} INFO - confs: [default]
[2024-05-20T00:00:09.979+0000] {spark_submit.py:571} INFO - 0 artifacts copied, 29 already retrieved (0kB/33ms)
[2024-05-20T00:00:10.443+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2024-05-20T00:00:13.413+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:13 INFO SparkContext: Running Spark version 3.5.1
[2024-05-20T00:00:13.420+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:13 INFO SparkContext: OS info Linux, 6.6.26-linuxkit, aarch64
[2024-05-20T00:00:13.421+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:13 INFO SparkContext: Java version 11.0.23
[2024-05-20T00:00:13.437+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:13 INFO ResourceUtils: ==============================================================
[2024-05-20T00:00:13.437+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:13 INFO ResourceUtils: No custom resources configured for spark.driver.
[2024-05-20T00:00:13.438+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:13 INFO ResourceUtils: ==============================================================
[2024-05-20T00:00:13.438+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:13 INFO SparkContext: Submitted application: Redfin_Properties_Consumer
[2024-05-20T00:00:13.468+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:13 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2024-05-20T00:00:13.491+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:13 INFO ResourceProfile: Limiting resource is cpu
[2024-05-20T00:00:13.492+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:13 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2024-05-20T00:00:13.589+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:13 INFO SecurityManager: Changing view acls to: ***
[2024-05-20T00:00:13.590+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:13 INFO SecurityManager: Changing modify acls to: ***
[2024-05-20T00:00:13.591+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:13 INFO SecurityManager: Changing view acls groups to:
[2024-05-20T00:00:13.591+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:13 INFO SecurityManager: Changing modify acls groups to:
[2024-05-20T00:00:13.591+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ***; groups with view permissions: EMPTY; users with modify permissions: ***; groups with modify permissions: EMPTY
[2024-05-20T00:00:14.008+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO Utils: Successfully started service 'sparkDriver' on port 44541.
[2024-05-20T00:00:14.058+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkEnv: Registering MapOutputTracker
[2024-05-20T00:00:14.132+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkEnv: Registering BlockManagerMaster
[2024-05-20T00:00:14.152+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2024-05-20T00:00:14.153+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2024-05-20T00:00:14.157+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2024-05-20T00:00:14.178+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0f91ea2e-9253-43b2-a3f1-bdf81469440c
[2024-05-20T00:00:14.188+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2024-05-20T00:00:14.198+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkEnv: Registering OutputCommitCoordinator
[2024-05-20T00:00:14.334+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2024-05-20T00:00:14.377+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2024-05-20T00:00:14.414+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar at spark://eddd84e36bad:44541/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar with timestamp 1716163213400
[2024-05-20T00:00:14.414+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar at spark://eddd84e36bad:44541/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1716163213400
[2024-05-20T00:00:14.414+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.kafka_kafka-clients-3.5.1.jar at spark://eddd84e36bad:44541/jars/org.apache.kafka_kafka-clients-3.5.1.jar with timestamp 1716163213400
[2024-05-20T00:00:14.415+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://eddd84e36bad:44541/jars/commons-logging_commons-logging-1.2.jar with timestamp 1716163213400
[2024-05-20T00:00:14.415+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar at spark://eddd84e36bad:44541/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar with timestamp 1716163213400
[2024-05-20T00:00:14.415+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://eddd84e36bad:44541/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1716163213400
[2024-05-20T00:00:14.415+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://eddd84e36bad:44541/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1716163213400
[2024-05-20T00:00:14.416+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://eddd84e36bad:44541/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1716163213400
[2024-05-20T00:00:14.416+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://eddd84e36bad:44541/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1716163213400
[2024-05-20T00:00:14.416+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://eddd84e36bad:44541/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1716163213400
[2024-05-20T00:00:14.416+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar at spark://eddd84e36bad:44541/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1716163213400
[2024-05-20T00:00:14.416+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar at spark://eddd84e36bad:44541/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1716163213400
[2024-05-20T00:00:14.417+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar at spark://eddd84e36bad:44541/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1716163213400
[2024-05-20T00:00:14.417+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar at spark://eddd84e36bad:44541/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1716163213400
[2024-05-20T00:00:14.417+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at spark://eddd84e36bad:44541/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1716163213400
[2024-05-20T00:00:14.417+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at spark://eddd84e36bad:44541/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1716163213400
[2024-05-20T00:00:14.418+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at spark://eddd84e36bad:44541/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1716163213400
[2024-05-20T00:00:14.418+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at spark://eddd84e36bad:44541/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1716163213400
[2024-05-20T00:00:14.418+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at spark://eddd84e36bad:44541/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1716163213400
[2024-05-20T00:00:14.418+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.typesafe_config-1.4.1.jar at spark://eddd84e36bad:44541/jars/com.typesafe_config-1.4.1.jar with timestamp 1716163213400
[2024-05-20T00:00:14.418+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at spark://eddd84e36bad:44541/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1716163213400
[2024-05-20T00:00:14.419+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at spark://eddd84e36bad:44541/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1716163213400
[2024-05-20T00:00:14.419+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at spark://eddd84e36bad:44541/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1716163213400
[2024-05-20T00:00:14.420+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at spark://eddd84e36bad:44541/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1716163213400
[2024-05-20T00:00:14.421+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at spark://eddd84e36bad:44541/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1716163213400
[2024-05-20T00:00:14.421+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at spark://eddd84e36bad:44541/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1716163213400
[2024-05-20T00:00:14.421+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar at spark://eddd84e36bad:44541/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1716163213400
[2024-05-20T00:00:14.422+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.github.luben_zstd-jni-1.5.5-1.jar at spark://eddd84e36bad:44541/jars/com.github.luben_zstd-jni-1.5.5-1.jar with timestamp 1716163213400
[2024-05-20T00:00:14.422+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at spark://eddd84e36bad:44541/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1716163213400
[2024-05-20T00:00:14.422+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar at spark://eddd84e36bad:44541/files/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar with timestamp 1716163213400
[2024-05-20T00:00:14.422+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.1.jar
[2024-05-20T00:00:14.442+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar at spark://eddd84e36bad:44541/files/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1716163213400
[2024-05-20T00:00:14.446+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO Utils: Copying /home/***/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2024-05-20T00:00:14.469+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.kafka_kafka-clients-3.5.1.jar at spark://eddd84e36bad:44541/files/org.apache.kafka_kafka-clients-3.5.1.jar with timestamp 1716163213400
[2024-05-20T00:00:14.469+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.kafka_kafka-clients-3.5.1.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/org.apache.kafka_kafka-clients-3.5.1.jar
[2024-05-20T00:00:14.570+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added file file:///home/***/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://eddd84e36bad:44541/files/commons-logging_commons-logging-1.2.jar with timestamp 1716163213400
[2024-05-20T00:00:14.572+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO Utils: Copying /home/***/.ivy2/jars/commons-logging_commons-logging-1.2.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/commons-logging_commons-logging-1.2.jar
[2024-05-20T00:00:14.586+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar at spark://eddd84e36bad:44541/files/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar with timestamp 1716163213400
[2024-05-20T00:00:14.587+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.1.jar
[2024-05-20T00:00:14.598+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://eddd84e36bad:44541/files/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1716163213400
[2024-05-20T00:00:14.598+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/org.apache.commons_commons-pool2-2.11.1.jar
[2024-05-20T00:00:14.611+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://eddd84e36bad:44541/files/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1716163213400
[2024-05-20T00:00:14.611+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:14 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2024-05-20T00:00:15.032+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:15 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://eddd84e36bad:44541/files/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1716163213400
[2024-05-20T00:00:15.032+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:15 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2024-05-20T00:00:16.604+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:16 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://eddd84e36bad:44541/files/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1716163213400
[2024-05-20T00:00:16.604+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:16 INFO Utils: Copying /home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2024-05-20T00:00:16.902+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:16 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://eddd84e36bad:44541/files/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1716163213400
[2024-05-20T00:00:16.902+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:16 INFO Utils: Copying /home/***/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/org.slf4j_slf4j-api-2.0.7.jar
[2024-05-20T00:00:16.931+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:16 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar at spark://eddd84e36bad:44541/files/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1716163213400
[2024-05-20T00:00:16.932+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:16 INFO Utils: Copying /home/***/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2024-05-20T00:00:17.054+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:17 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar at spark://eddd84e36bad:44541/files/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1716163213400
[2024-05-20T00:00:17.054+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:17 INFO Utils: Copying /home/***/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2024-05-20T00:00:17.128+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:17 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar at spark://eddd84e36bad:44541/files/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1716163213400
[2024-05-20T00:00:17.130+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:17 INFO Utils: Copying /home/***/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2024-05-20T00:00:17.967+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:17 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar at spark://eddd84e36bad:44541/files/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1716163213400
[2024-05-20T00:00:17.968+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:17 INFO Utils: Copying /home/***/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2024-05-20T00:00:18.011+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at spark://eddd84e36bad:44541/files/org.apache.commons_commons-lang3-3.10.jar with timestamp 1716163213400
[2024-05-20T00:00:18.011+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/org.apache.commons_commons-lang3-3.10.jar
[2024-05-20T00:00:18.147+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at spark://eddd84e36bad:44541/files/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1716163213400
[2024-05-20T00:00:18.148+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO Utils: Copying /home/***/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/com.thoughtworks.paranamer_paranamer-2.8.jar
[2024-05-20T00:00:18.192+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at spark://eddd84e36bad:44541/files/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1716163213400
[2024-05-20T00:00:18.193+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO Utils: Copying /home/***/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/org.scala-lang_scala-reflect-2.12.11.jar
[2024-05-20T00:00:18.863+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at spark://eddd84e36bad:44541/files/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1716163213400
[2024-05-20T00:00:18.864+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO Utils: Copying /home/***/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/com.datastax.oss_native-protocol-1.5.0.jar
[2024-05-20T00:00:18.891+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at spark://eddd84e36bad:44541/files/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1716163213400
[2024-05-20T00:00:18.892+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO Utils: Copying /home/***/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2024-05-20T00:00:18.936+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.typesafe_config-1.4.1.jar at spark://eddd84e36bad:44541/files/com.typesafe_config-1.4.1.jar with timestamp 1716163213400
[2024-05-20T00:00:18.937+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO Utils: Copying /home/***/.ivy2/jars/com.typesafe_config-1.4.1.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/com.typesafe_config-1.4.1.jar
[2024-05-20T00:00:18.948+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO SparkContext: Added file file:///home/***/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at spark://eddd84e36bad:44541/files/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1716163213400
[2024-05-20T00:00:18.948+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO Utils: Copying /home/***/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2024-05-20T00:00:18.957+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at spark://eddd84e36bad:44541/files/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1716163213400
[2024-05-20T00:00:18.957+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO Utils: Copying /home/***/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2024-05-20T00:00:18.965+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at spark://eddd84e36bad:44541/files/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1716163213400
[2024-05-20T00:00:18.966+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:18 INFO Utils: Copying /home/***/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/org.reactivestreams_reactive-streams-1.0.3.jar
[2024-05-20T00:00:19.005+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:19 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at spark://eddd84e36bad:44541/files/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1716163213400
[2024-05-20T00:00:19.009+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:19 INFO Utils: Copying /home/***/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2024-05-20T00:00:19.028+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:19 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at spark://eddd84e36bad:44541/files/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1716163213400
[2024-05-20T00:00:19.028+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:19 INFO Utils: Copying /home/***/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2024-05-20T00:00:19.074+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:19 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at spark://eddd84e36bad:44541/files/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1716163213400
[2024-05-20T00:00:19.074+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:19 INFO Utils: Copying /home/***/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/com.google.code.findbugs_jsr305-3.0.2.jar
[2024-05-20T00:00:19.091+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:19 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar at spark://eddd84e36bad:44541/files/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1716163213400
[2024-05-20T00:00:19.091+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:19 INFO Utils: Copying /home/***/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2024-05-20T00:00:19.161+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:19 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.github.luben_zstd-jni-1.5.5-1.jar at spark://eddd84e36bad:44541/files/com.github.luben_zstd-jni-1.5.5-1.jar with timestamp 1716163213400
[2024-05-20T00:00:19.162+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:19 INFO Utils: Copying /home/***/.ivy2/jars/com.github.luben_zstd-jni-1.5.5-1.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/com.github.luben_zstd-jni-1.5.5-1.jar
[2024-05-20T00:00:20.273+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:20 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at spark://eddd84e36bad:44541/files/org.lz4_lz4-java-1.8.0.jar with timestamp 1716163213400
[2024-05-20T00:00:20.274+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:20 INFO Utils: Copying /home/***/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-5a5cb2cd-cb70-434e-9242-7c4def58f7d1/userFiles-fc6144cb-1dcb-4c5a-a5ec-3ef2d7a9b1cf/org.lz4_lz4-java-1.8.0.jar
[2024-05-20T00:00:20.584+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:20 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2024-05-20T00:00:20.655+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:20 INFO TransportClientFactory: Successfully created connection to spark-master/192.168.96.3:7077 after 31 ms (0 ms spent in bootstraps)
[2024-05-20T00:00:21.123+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:21 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240520000021-0007
[2024-05-20T00:00:21.134+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43929.
[2024-05-20T00:00:21.135+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:21 INFO NettyBlockTransferService: Server created on eddd84e36bad:43929
[2024-05-20T00:00:21.137+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2024-05-20T00:00:21.144+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, eddd84e36bad, 43929, None)
[2024-05-20T00:00:21.147+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:21 INFO BlockManagerMasterEndpoint: Registering block manager eddd84e36bad:43929 with 434.4 MiB RAM, BlockManagerId(driver, eddd84e36bad, 43929, None)
[2024-05-20T00:00:21.151+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, eddd84e36bad, 43929, None)
[2024-05-20T00:00:21.152+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, eddd84e36bad, 43929, None)
[2024-05-20T00:00:21.153+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240520000021-0007/0 on worker-20240519000616-192.168.96.6-36477 (192.168.96.6:36477) with 1 core(s)
[2024-05-20T00:00:21.154+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20240520000021-0007/0 on hostPort 192.168.96.6:36477 with 1 core(s), 1024.0 MiB RAM
[2024-05-20T00:00:21.456+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:21 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2024-05-20T00:00:21.740+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240520000021-0007/0 is now RUNNING
[2024-05-20T00:00:21.799+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:21 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2024-05-20T00:00:21.801+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:21 INFO SharedState: Warehouse path is 'file:/opt/***/spark-warehouse'.
[2024-05-20T00:00:26.095+0000] {spark_submit.py:571} INFO - INFO:py4j.java_gateway:Callback Server Starting
[2024-05-20T00:00:26.104+0000] {spark_submit.py:571} INFO - INFO:py4j.java_gateway:Socket listening on ('127.0.0.1', 46149)
[2024-05-20T00:00:26.139+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:26 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
[2024-05-20T00:00:26.225+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:26 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.
[2024-05-20T00:00:26.286+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:26 INFO ResolveWriteToStream: Checkpoint root file:///tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba resolved to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba.
[2024-05-20T00:00:26.287+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:26 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2024-05-20T00:00:26.474+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/metadata using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/.metadata.02ee89de-251a-4f56-91e2-5876d5ef1d6f.tmp
[2024-05-20T00:00:26.643+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/.metadata.02ee89de-251a-4f56-91e2-5876d5ef1d6f.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/metadata
[2024-05-20T00:00:26.706+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:26 INFO MicroBatchExecution: Starting [id = 483fceee-2997-4112-9685-5530c8c769e0, runId = f4941a1d-2d71-4d43-9364-aeb0c5b4b17e]. Use file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba to store the query checkpoint.
[2024-05-20T00:00:26.730+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:26 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@788b2c6d] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@243b0dd8]
[2024-05-20T00:00:26.867+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:26 INFO OffsetSeqLog: BatchIds found from listing:
[2024-05-20T00:00:26.870+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:26 INFO OffsetSeqLog: BatchIds found from listing:
[2024-05-20T00:00:26.871+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:26 INFO MicroBatchExecution: Starting new streaming query.
[2024-05-20T00:00:26.875+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:26 INFO MicroBatchExecution: Stream started from {}
[2024-05-20T00:00:27.808+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:27 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.96.6:33174) with ID 0,  ResourceProfileId 0
[2024-05-20T00:00:28.021+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:28 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.96.6:44029 with 434.4 MiB RAM, BlockManagerId(0, 192.168.96.6, 44029, None)
[2024-05-20T00:00:28.113+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:28 INFO AdminClientConfig: AdminClientConfig values:
[2024-05-20T00:00:28.114+0000] {spark_submit.py:571} INFO - auto.include.jmx.reporter = true
[2024-05-20T00:00:28.114+0000] {spark_submit.py:571} INFO - bootstrap.servers = [kafka:9092]
[2024-05-20T00:00:28.114+0000] {spark_submit.py:571} INFO - client.dns.lookup = use_all_dns_ips
[2024-05-20T00:00:28.114+0000] {spark_submit.py:571} INFO - client.id =
[2024-05-20T00:00:28.115+0000] {spark_submit.py:571} INFO - connections.max.idle.ms = 300000
[2024-05-20T00:00:28.115+0000] {spark_submit.py:571} INFO - default.api.timeout.ms = 60000
[2024-05-20T00:00:28.115+0000] {spark_submit.py:571} INFO - metadata.max.age.ms = 300000
[2024-05-20T00:00:28.118+0000] {spark_submit.py:571} INFO - metric.reporters = []
[2024-05-20T00:00:28.118+0000] {spark_submit.py:571} INFO - metrics.num.samples = 2
[2024-05-20T00:00:28.119+0000] {spark_submit.py:571} INFO - metrics.recording.level = INFO
[2024-05-20T00:00:28.119+0000] {spark_submit.py:571} INFO - metrics.sample.window.ms = 30000
[2024-05-20T00:00:28.119+0000] {spark_submit.py:571} INFO - receive.buffer.bytes = 65536
[2024-05-20T00:00:28.119+0000] {spark_submit.py:571} INFO - reconnect.backoff.max.ms = 1000
[2024-05-20T00:00:28.119+0000] {spark_submit.py:571} INFO - reconnect.backoff.ms = 50
[2024-05-20T00:00:28.119+0000] {spark_submit.py:571} INFO - request.timeout.ms = 30000
[2024-05-20T00:00:28.119+0000] {spark_submit.py:571} INFO - retries = 2147483647
[2024-05-20T00:00:28.120+0000] {spark_submit.py:571} INFO - retry.backoff.ms = 100
[2024-05-20T00:00:28.120+0000] {spark_submit.py:571} INFO - sasl.client.callback.handler.class = null
[2024-05-20T00:00:28.120+0000] {spark_submit.py:571} INFO - sasl.jaas.config = null
[2024-05-20T00:00:28.120+0000] {spark_submit.py:571} INFO - sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2024-05-20T00:00:28.120+0000] {spark_submit.py:571} INFO - sasl.kerberos.min.time.before.relogin = 60000
[2024-05-20T00:00:28.121+0000] {spark_submit.py:571} INFO - sasl.kerberos.service.name = null
[2024-05-20T00:00:28.121+0000] {spark_submit.py:571} INFO - sasl.kerberos.ticket.renew.jitter = 0.05
[2024-05-20T00:00:28.121+0000] {spark_submit.py:571} INFO - sasl.kerberos.ticket.renew.window.factor = 0.8
[2024-05-20T00:00:28.121+0000] {spark_submit.py:571} INFO - sasl.login.callback.handler.class = null
[2024-05-20T00:00:28.122+0000] {spark_submit.py:571} INFO - sasl.login.class = null
[2024-05-20T00:00:28.122+0000] {spark_submit.py:571} INFO - sasl.login.connect.timeout.ms = null
[2024-05-20T00:00:28.122+0000] {spark_submit.py:571} INFO - sasl.login.read.timeout.ms = null
[2024-05-20T00:00:28.122+0000] {spark_submit.py:571} INFO - sasl.login.refresh.buffer.seconds = 300
[2024-05-20T00:00:28.123+0000] {spark_submit.py:571} INFO - sasl.login.refresh.min.period.seconds = 60
[2024-05-20T00:00:28.123+0000] {spark_submit.py:571} INFO - sasl.login.refresh.window.factor = 0.8
[2024-05-20T00:00:28.123+0000] {spark_submit.py:571} INFO - sasl.login.refresh.window.jitter = 0.05
[2024-05-20T00:00:28.124+0000] {spark_submit.py:571} INFO - sasl.login.retry.backoff.max.ms = 10000
[2024-05-20T00:00:28.124+0000] {spark_submit.py:571} INFO - sasl.login.retry.backoff.ms = 100
[2024-05-20T00:00:28.125+0000] {spark_submit.py:571} INFO - sasl.mechanism = GSSAPI
[2024-05-20T00:00:28.125+0000] {spark_submit.py:571} INFO - sasl.oauthbearer.clock.skew.seconds = 30
[2024-05-20T00:00:28.125+0000] {spark_submit.py:571} INFO - sasl.oauthbearer.expected.audience = null
[2024-05-20T00:00:28.125+0000] {spark_submit.py:571} INFO - sasl.oauthbearer.expected.issuer = null
[2024-05-20T00:00:28.126+0000] {spark_submit.py:571} INFO - sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2024-05-20T00:00:28.126+0000] {spark_submit.py:571} INFO - sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2024-05-20T00:00:28.126+0000] {spark_submit.py:571} INFO - sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2024-05-20T00:00:28.127+0000] {spark_submit.py:571} INFO - sasl.oauthbearer.jwks.endpoint.url = null
[2024-05-20T00:00:28.128+0000] {spark_submit.py:571} INFO - sasl.oauthbearer.scope.claim.name = scope
[2024-05-20T00:00:28.128+0000] {spark_submit.py:571} INFO - sasl.oauthbearer.sub.claim.name = sub
[2024-05-20T00:00:28.129+0000] {spark_submit.py:571} INFO - sasl.oauthbearer.token.endpoint.url = null
[2024-05-20T00:00:28.129+0000] {spark_submit.py:571} INFO - security.protocol = PLAINTEXT
[2024-05-20T00:00:28.130+0000] {spark_submit.py:571} INFO - security.providers = null
[2024-05-20T00:00:28.130+0000] {spark_submit.py:571} INFO - send.buffer.bytes = 131072
[2024-05-20T00:00:28.131+0000] {spark_submit.py:571} INFO - socket.connection.setup.timeout.max.ms = 30000
[2024-05-20T00:00:28.131+0000] {spark_submit.py:571} INFO - socket.connection.setup.timeout.ms = 10000
[2024-05-20T00:00:28.132+0000] {spark_submit.py:571} INFO - ssl.cipher.suites = null
[2024-05-20T00:00:28.132+0000] {spark_submit.py:571} INFO - ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2024-05-20T00:00:28.133+0000] {spark_submit.py:571} INFO - ssl.endpoint.identification.algorithm = https
[2024-05-20T00:00:28.134+0000] {spark_submit.py:571} INFO - ssl.engine.factory.class = null
[2024-05-20T00:00:28.134+0000] {spark_submit.py:571} INFO - ssl.key.password = null
[2024-05-20T00:00:28.135+0000] {spark_submit.py:571} INFO - ssl.keymanager.algorithm = SunX509
[2024-05-20T00:00:28.136+0000] {spark_submit.py:571} INFO - ssl.keystore.certificate.chain = null
[2024-05-20T00:00:28.136+0000] {spark_submit.py:571} INFO - ssl.keystore.key = null
[2024-05-20T00:00:28.137+0000] {spark_submit.py:571} INFO - ssl.keystore.location = null
[2024-05-20T00:00:28.137+0000] {spark_submit.py:571} INFO - ssl.keystore.password = null
[2024-05-20T00:00:28.137+0000] {spark_submit.py:571} INFO - ssl.keystore.type = JKS
[2024-05-20T00:00:28.138+0000] {spark_submit.py:571} INFO - ssl.protocol = TLSv1.3
[2024-05-20T00:00:28.138+0000] {spark_submit.py:571} INFO - ssl.provider = null
[2024-05-20T00:00:28.138+0000] {spark_submit.py:571} INFO - ssl.secure.random.implementation = null
[2024-05-20T00:00:28.138+0000] {spark_submit.py:571} INFO - ssl.trustmanager.algorithm = PKIX
[2024-05-20T00:00:28.138+0000] {spark_submit.py:571} INFO - ssl.truststore.certificates = null
[2024-05-20T00:00:28.139+0000] {spark_submit.py:571} INFO - ssl.truststore.location = null
[2024-05-20T00:00:28.139+0000] {spark_submit.py:571} INFO - ssl.truststore.password = null
[2024-05-20T00:00:28.139+0000] {spark_submit.py:571} INFO - ssl.truststore.type = JKS
[2024-05-20T00:00:28.139+0000] {spark_submit.py:571} INFO - 
[2024-05-20T00:00:28.315+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:28 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2024-05-20T00:00:28.322+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:28 INFO AppInfoParser: Kafka version: 3.5.1
[2024-05-20T00:00:28.323+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:28 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2024-05-20T00:00:28.327+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:28 INFO AppInfoParser: Kafka startTimeMs: 1716163228315
[2024-05-20T00:00:29.325+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/sources/0/0 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/sources/0/.0.6bd91255-8fa5-41da-b739-e048b6e30966.tmp
[2024-05-20T00:00:29.416+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/sources/0/.0.6bd91255-8fa5-41da-b739-e048b6e30966.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/sources/0/0
[2024-05-20T00:00:29.417+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:29 INFO KafkaMicroBatchStream: Initial offsets: {"redfin_properties":{"0":0}}
[2024-05-20T00:00:29.509+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/0 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.0.350ec429-7081-4658-9a8b-4d358ce6d6bd.tmp
[2024-05-20T00:00:29.641+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.0.350ec429-7081-4658-9a8b-4d358ce6d6bd.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/0
[2024-05-20T00:00:29.644+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:29 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1716163229439,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:00:31.239+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:31 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:00:31.392+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:31 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:00:31.515+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:31 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:00:31.517+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:31 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:00:32.884+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:32 INFO CodeGenerator: Code generated in 790.292833 ms
[2024-05-20T00:00:33.193+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Python Server ready to receive messages
[2024-05-20T00:00:33.196+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:00:33.411+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:33 INFO CodeGenerator: Code generated in 132.544625 ms
[2024-05-20T00:00:33.997+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:33 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:00:34.028+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:34 INFO DAGScheduler: Got job 0 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:00:34.030+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:34 INFO DAGScheduler: Final stage: ResultStage 0 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:00:34.031+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:34 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:00:34.031+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:34 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:00:34.039+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:34 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[9] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:00:34.224+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:00:34.404+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:00:34.409+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:00:34.414+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:00:34.470+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (PythonRDD[9] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:00:34.471+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2024-05-20T00:00:36.457+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:00:39.789+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:00:59.962+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 23826 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:00:59.968+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2024-05-20T00:00:59.976+0000] {spark_submit.py:571} INFO - 24/05/20 00:00:59 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 36791
[2024-05-20T00:01:00.016+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:00 INFO DAGScheduler: ResultStage 0 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 25.904 s
[2024-05-20T00:01:00.028+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:00 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:01:00.031+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2024-05-20T00:01:00.045+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:00 INFO DAGScheduler: Job 0 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 26.050431 s
[2024-05-20T00:01:00.197+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/0 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.0.cd10b858-eaf2-4ccb-a69c-2f97e67c5f06.tmp
[2024-05-20T00:01:00.264+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.0.cd10b858-eaf2-4ccb-a69c-2f97e67c5f06.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/0
[2024-05-20T00:01:00.395+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:00 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:01:00.396+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:01:00.396+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:01:00.396+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:01:00.396+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:00:26.851Z",
[2024-05-20T00:01:00.397+0000] {spark_submit.py:571} INFO - "batchId" : 0,
[2024-05-20T00:01:00.397+0000] {spark_submit.py:571} INFO - "numInputRows" : 24,
[2024-05-20T00:01:00.397+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 0.0,
[2024-05-20T00:01:00.397+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7181973247149654,
[2024-05-20T00:01:00.397+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:01:00.397+0000] {spark_submit.py:571} INFO - "addBatch" : 28680,
[2024-05-20T00:01:00.397+0000] {spark_submit.py:571} INFO - "commitOffsets" : 130,
[2024-05-20T00:01:00.397+0000] {spark_submit.py:571} INFO - "getBatch" : 175,
[2024-05-20T00:01:00.398+0000] {spark_submit.py:571} INFO - "latestOffset" : 2556,
[2024-05-20T00:01:00.398+0000] {spark_submit.py:571} INFO - "queryPlanning" : 1591,
[2024-05-20T00:01:00.398+0000] {spark_submit.py:571} INFO - "triggerExecution" : 33414,
[2024-05-20T00:01:00.398+0000] {spark_submit.py:571} INFO - "walCommit" : 195
[2024-05-20T00:01:00.398+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:01:00.398+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:01:00.398+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:01:00.399+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:01:00.399+0000] {spark_submit.py:571} INFO - "startOffset" : null,
[2024-05-20T00:01:00.399+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:01:00.399+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:01:00.399+0000] {spark_submit.py:571} INFO - "0" : 24
[2024-05-20T00:01:00.399+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:00.399+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:01:00.400+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:01:00.400+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:01:00.400+0000] {spark_submit.py:571} INFO - "0" : 24
[2024-05-20T00:01:00.400+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:00.400+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:01:00.400+0000] {spark_submit.py:571} INFO - "numInputRows" : 24,
[2024-05-20T00:01:00.400+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 0.0,
[2024-05-20T00:01:00.400+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7181973247149654,
[2024-05-20T00:01:00.401+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:01:00.401+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:01:00.401+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:01:00.401+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:01:00.401+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:00.401+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:01:00.401+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:01:00.401+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:01:00.402+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:01:00.402+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:00.402+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:00.430+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/1 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.1.9f5f59f0-d7c7-4f99-8205-8fe6f3c19650.tmp
[2024-05-20T00:01:00.484+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.1.9f5f59f0-d7c7-4f99-8205-8fe6f3c19650.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/1
[2024-05-20T00:01:00.485+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:00 INFO MicroBatchExecution: Committed offsets for batch 1. Metadata OffsetSeqMetadata(0,1716163260419,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:01:00.718+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:01:00.753+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:01:01.057+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO BlockManagerInfo: Removed broadcast_0_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:01:01.072+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:01:01.075+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:01:01.124+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:01:01.231+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:01:01.513+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:01:01.515+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO DAGScheduler: Got job 1 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:01:01.515+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO DAGScheduler: Final stage: ResultStage 1 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:01:01.516+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:01:01.516+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:01:01.517+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[19] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:01:01.525+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:01:01.544+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:01:01.545+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:01:01.547+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:01:01.548+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (PythonRDD[19] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:01:01.549+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2024-05-20T00:01:01.553+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:01:01.603+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:01:02.418+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 858 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:01:02.436+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2024-05-20T00:01:02.443+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:02 INFO DAGScheduler: ResultStage 1 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.917 s
[2024-05-20T00:01:02.446+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:02 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:01:02.447+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2024-05-20T00:01:02.455+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:02 INFO DAGScheduler: Job 1 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.940513 s
[2024-05-20T00:01:02.618+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/1 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.1.e74f28e7-b55b-408d-8a46-4c7eb4db0c0a.tmp
[2024-05-20T00:01:02.672+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.1.e74f28e7-b55b-408d-8a46-4c7eb4db0c0a.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/1
[2024-05-20T00:01:02.680+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:02 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:01:02.680+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:01:02.681+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:01:02.681+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:01:02.681+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:01:00.396Z",
[2024-05-20T00:01:02.681+0000] {spark_submit.py:571} INFO - "batchId" : 1,
[2024-05-20T00:01:02.681+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:01:02.681+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 0.029810702042033087,
[2024-05-20T00:01:02.682+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.4393673110720563,
[2024-05-20T00:01:02.682+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:01:02.682+0000] {spark_submit.py:571} INFO - "addBatch" : 1531,
[2024-05-20T00:01:02.682+0000] {spark_submit.py:571} INFO - "commitOffsets" : 140,
[2024-05-20T00:01:02.683+0000] {spark_submit.py:571} INFO - "getBatch" : 1,
[2024-05-20T00:01:02.683+0000] {spark_submit.py:571} INFO - "latestOffset" : 22,
[2024-05-20T00:01:02.683+0000] {spark_submit.py:571} INFO - "queryPlanning" : 267,
[2024-05-20T00:01:02.684+0000] {spark_submit.py:571} INFO - "triggerExecution" : 2276,
[2024-05-20T00:01:02.684+0000] {spark_submit.py:571} INFO - "walCommit" : 66
[2024-05-20T00:01:02.688+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:01:02.689+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:01:02.690+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:01:02.691+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:01:02.693+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:01:02.696+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:01:02.698+0000] {spark_submit.py:571} INFO - "0" : 24
[2024-05-20T00:01:02.698+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:02.699+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:01:02.700+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:01:02.700+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:01:02.701+0000] {spark_submit.py:571} INFO - "0" : 25
[2024-05-20T00:01:02.701+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:02.701+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:01:02.701+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:01:02.702+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:01:02.702+0000] {spark_submit.py:571} INFO - "0" : 25
[2024-05-20T00:01:02.702+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:02.702+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:01:02.702+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:01:02.703+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 0.029810702042033087,
[2024-05-20T00:01:02.703+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.4393673110720563,
[2024-05-20T00:01:02.703+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:01:02.703+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:01:02.703+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:01:02.703+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:01:02.703+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:02.704+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:01:02.704+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:01:02.704+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:01:02.704+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:01:02.705+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:02.705+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:12.702+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:01:22.688+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:01:23.814+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/2 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.2.40e219cd-fbbc-41a0-afd0-7a25847f1bfe.tmp
[2024-05-20T00:01:23.849+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.2.40e219cd-fbbc-41a0-afd0-7a25847f1bfe.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/2
[2024-05-20T00:01:23.849+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:23 INFO MicroBatchExecution: Committed offsets for batch 2. Metadata OffsetSeqMetadata(0,1716163283774,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:01:23.919+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:23 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:01:23.924+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:23 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:01:23.954+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:23 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:01:23.956+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:23 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:01:24.012+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:01:24.081+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:24 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:01:24.083+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:24 INFO DAGScheduler: Got job 2 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:01:24.083+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:24 INFO DAGScheduler: Final stage: ResultStage 2 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:01:24.084+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:24 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:01:24.084+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:24 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:01:24.084+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:24 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[29] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:01:24.088+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 69.8 KiB, free 434.2 MiB)
[2024-05-20T00:01:24.128+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.2 MiB)
[2024-05-20T00:01:24.129+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:01:24.130+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:01:24.131+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (PythonRDD[29] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:01:24.131+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2024-05-20T00:01:24.134+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:01:24.215+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:01:25.183+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1046 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:01:25.190+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2024-05-20T00:01:25.195+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:25 INFO DAGScheduler: ResultStage 2 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 1.107 s
[2024-05-20T00:01:25.197+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:25 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:01:25.197+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2024-05-20T00:01:25.199+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:25 INFO DAGScheduler: Job 2 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 1.117061 s
[2024-05-20T00:01:25.263+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/2 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.2.6bcfaf62-5f96-4b77-a73e-06f2618bb471.tmp
[2024-05-20T00:01:25.397+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.2.6bcfaf62-5f96-4b77-a73e-06f2618bb471.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/2
[2024-05-20T00:01:25.405+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:25 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:01:25.406+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:01:25.406+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:01:25.406+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:01:25.407+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:01:23.772Z",
[2024-05-20T00:01:25.408+0000] {spark_submit.py:571} INFO - "batchId" : 2,
[2024-05-20T00:01:25.408+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:01:25.408+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 83.33333333333333,
[2024-05-20T00:01:25.408+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.6150061500615006,
[2024-05-20T00:01:25.408+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:01:25.408+0000] {spark_submit.py:571} INFO - "addBatch" : 1296,
[2024-05-20T00:01:25.409+0000] {spark_submit.py:571} INFO - "commitOffsets" : 168,
[2024-05-20T00:01:25.409+0000] {spark_submit.py:571} INFO - "getBatch" : 1,
[2024-05-20T00:01:25.424+0000] {spark_submit.py:571} INFO - "latestOffset" : 2,
[2024-05-20T00:01:25.425+0000] {spark_submit.py:571} INFO - "queryPlanning" : 75,
[2024-05-20T00:01:25.425+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1626,
[2024-05-20T00:01:25.425+0000] {spark_submit.py:571} INFO - "walCommit" : 76
[2024-05-20T00:01:25.426+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:01:25.426+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:01:25.426+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:01:25.426+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:01:25.426+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:01:25.426+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:01:25.426+0000] {spark_submit.py:571} INFO - "0" : 25
[2024-05-20T00:01:25.427+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:25.427+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:01:25.427+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:01:25.427+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:01:25.428+0000] {spark_submit.py:571} INFO - "0" : 26
[2024-05-20T00:01:25.428+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:25.429+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:01:25.430+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:01:25.430+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:01:25.430+0000] {spark_submit.py:571} INFO - "0" : 26
[2024-05-20T00:01:25.430+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:25.431+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:01:25.431+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:01:25.432+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 83.33333333333333,
[2024-05-20T00:01:25.432+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.6150061500615006,
[2024-05-20T00:01:25.432+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:01:25.432+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:01:25.432+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:01:25.432+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:01:25.432+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:25.433+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:01:25.433+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:01:25.433+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:01:25.433+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:01:25.433+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:25.433+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:01:33.856+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:01:33.873+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:01:33.881+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:33 INFO BlockManagerInfo: Removed broadcast_2_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:01:33.884+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:33 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:01:35.415+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:01:45.419+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:01:55.429+0000] {spark_submit.py:571} INFO - 24/05/20 00:01:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:02:02.326+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/3 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.3.8500668c-f2ba-4a47-ab95-30b9e8f48a31.tmp
[2024-05-20T00:02:02.376+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.3.8500668c-f2ba-4a47-ab95-30b9e8f48a31.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/3
[2024-05-20T00:02:02.378+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO MicroBatchExecution: Committed offsets for batch 3. Metadata OffsetSeqMetadata(0,1716163322264,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:02:02.466+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:02:02.469+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:02:02.493+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:02:02.494+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:02:02.552+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:02:02.643+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:02:02.645+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO DAGScheduler: Got job 3 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:02:02.645+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO DAGScheduler: Final stage: ResultStage 3 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:02:02.646+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:02:02.646+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:02:02.646+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO DAGScheduler: Submitting ResultStage 3 (PythonRDD[39] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:02:02.651+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:02:02.662+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:02:02.663+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:02:02.664+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:02:02.665+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (PythonRDD[39] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:02:02.665+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2024-05-20T00:02:02.668+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:02:02.760+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:02:03.593+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:03 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 922 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:02:03.598+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:03 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2024-05-20T00:02:03.599+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:03 INFO DAGScheduler: ResultStage 3 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.950 s
[2024-05-20T00:02:03.600+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:03 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:02:03.601+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2024-05-20T00:02:03.607+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:03 INFO DAGScheduler: Job 3 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.963492 s
[2024-05-20T00:02:03.675+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/3 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.3.2deb2dfe-b0dc-4193-8b45-18f2dd2ed835.tmp
[2024-05-20T00:02:03.728+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.3.2deb2dfe-b0dc-4193-8b45-18f2dd2ed835.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/3
[2024-05-20T00:02:03.733+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:03 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:02:03.733+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:02:03.733+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:02:03.733+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:02:03.734+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:02:02.262Z",
[2024-05-20T00:02:03.735+0000] {spark_submit.py:571} INFO - "batchId" : 3,
[2024-05-20T00:02:03.735+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:02:03.735+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 66.66666666666667,
[2024-05-20T00:02:03.735+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.6821282401091405,
[2024-05-20T00:02:03.736+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:02:03.736+0000] {spark_submit.py:571} INFO - "addBatch" : 1166,
[2024-05-20T00:02:03.737+0000] {spark_submit.py:571} INFO - "commitOffsets" : 84,
[2024-05-20T00:02:03.737+0000] {spark_submit.py:571} INFO - "getBatch" : 0,
[2024-05-20T00:02:03.737+0000] {spark_submit.py:571} INFO - "latestOffset" : 2,
[2024-05-20T00:02:03.737+0000] {spark_submit.py:571} INFO - "queryPlanning" : 85,
[2024-05-20T00:02:03.737+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1466,
[2024-05-20T00:02:03.737+0000] {spark_submit.py:571} INFO - "walCommit" : 115
[2024-05-20T00:02:03.737+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:02:03.738+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:02:03.738+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:02:03.738+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:02:03.738+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:02:03.738+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:02:03.738+0000] {spark_submit.py:571} INFO - "0" : 26
[2024-05-20T00:02:03.738+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:03.738+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:02:03.738+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:02:03.739+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:02:03.739+0000] {spark_submit.py:571} INFO - "0" : 27
[2024-05-20T00:02:03.739+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:03.739+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:02:03.739+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:02:03.739+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:02:03.739+0000] {spark_submit.py:571} INFO - "0" : 27
[2024-05-20T00:02:03.740+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:03.740+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:02:03.740+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:02:03.740+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 66.66666666666667,
[2024-05-20T00:02:03.740+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.6821282401091405,
[2024-05-20T00:02:03.740+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:02:03.740+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:02:03.740+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:02:03.740+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:02:03.741+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:03.741+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:02:03.741+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:02:03.741+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:02:03.741+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:02:03.741+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:03.741+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:08.100+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:08 INFO BlockManagerInfo: Removed broadcast_3_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:02:08.130+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:08 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:02:13.742+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:02:23.746+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:02:32.130+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/4 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.4.6694d922-6976-40bb-b640-e1fa0c29f6ae.tmp
[2024-05-20T00:02:32.163+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.4.6694d922-6976-40bb-b640-e1fa0c29f6ae.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/4
[2024-05-20T00:02:32.163+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO MicroBatchExecution: Committed offsets for batch 4. Metadata OffsetSeqMetadata(0,1716163352085,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:02:32.220+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:02:32.227+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:02:32.250+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:02:32.252+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:02:32.297+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:02:32.396+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:02:32.398+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO DAGScheduler: Got job 4 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:02:32.398+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO DAGScheduler: Final stage: ResultStage 4 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:02:32.398+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:02:32.399+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:02:32.399+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO DAGScheduler: Submitting ResultStage 4 (PythonRDD[49] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:02:32.403+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:02:32.428+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:02:32.430+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:02:32.430+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:02:32.432+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (PythonRDD[49] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:02:32.433+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2024-05-20T00:02:32.435+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:02:32.510+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:02:33.276+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:33 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 835 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:02:33.292+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:33 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2024-05-20T00:02:33.292+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:33 INFO DAGScheduler: ResultStage 4 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.881 s
[2024-05-20T00:02:33.293+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:33 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:02:33.294+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
[2024-05-20T00:02:33.294+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:33 INFO DAGScheduler: Job 4 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.891626 s
[2024-05-20T00:02:33.361+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/4 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.4.8047ba46-d0e1-47f0-bd2b-07a7f384e2ec.tmp
[2024-05-20T00:02:33.398+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.4.8047ba46-d0e1-47f0-bd2b-07a7f384e2ec.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/4
[2024-05-20T00:02:33.403+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:33 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:02:33.403+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:02:33.403+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:02:33.404+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:02:33.404+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:02:32.084Z",
[2024-05-20T00:02:33.404+0000] {spark_submit.py:571} INFO - "batchId" : 4,
[2024-05-20T00:02:33.404+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:02:33.404+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 71.42857142857143,
[2024-05-20T00:02:33.405+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.76103500761035,
[2024-05-20T00:02:33.405+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:02:33.405+0000] {spark_submit.py:571} INFO - "addBatch" : 1074,
[2024-05-20T00:02:33.406+0000] {spark_submit.py:571} INFO - "commitOffsets" : 89,
[2024-05-20T00:02:33.406+0000] {spark_submit.py:571} INFO - "getBatch" : 0,
[2024-05-20T00:02:33.406+0000] {spark_submit.py:571} INFO - "latestOffset" : 1,
[2024-05-20T00:02:33.406+0000] {spark_submit.py:571} INFO - "queryPlanning" : 64,
[2024-05-20T00:02:33.406+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1314,
[2024-05-20T00:02:33.406+0000] {spark_submit.py:571} INFO - "walCommit" : 78
[2024-05-20T00:02:33.406+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:02:33.407+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:02:33.407+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:02:33.407+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:02:33.407+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:02:33.407+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:02:33.407+0000] {spark_submit.py:571} INFO - "0" : 27
[2024-05-20T00:02:33.407+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:33.407+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:02:33.408+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:02:33.408+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:02:33.408+0000] {spark_submit.py:571} INFO - "0" : 28
[2024-05-20T00:02:33.408+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:33.408+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:02:33.408+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:02:33.408+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:02:33.408+0000] {spark_submit.py:571} INFO - "0" : 28
[2024-05-20T00:02:33.408+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:33.408+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:02:33.408+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:02:33.408+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 71.42857142857143,
[2024-05-20T00:02:33.408+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.76103500761035,
[2024-05-20T00:02:33.409+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:02:33.409+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:02:33.409+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:02:33.409+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:02:33.409+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:33.409+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:02:33.409+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:02:33.409+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:02:33.409+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:02:33.409+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:33.409+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:43.407+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:02:53.411+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:02:57.492+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/5 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.5.4fbd6ef4-b33f-43fe-831b-d0d3b1ded7ed.tmp
[2024-05-20T00:02:57.552+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.5.4fbd6ef4-b33f-43fe-831b-d0d3b1ded7ed.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/5
[2024-05-20T00:02:57.553+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO MicroBatchExecution: Committed offsets for batch 5. Metadata OffsetSeqMetadata(0,1716163377451,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:02:57.613+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:02:57.618+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:02:57.648+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:02:57.649+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:02:57.706+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:02:57.755+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:02:57.757+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO DAGScheduler: Got job 5 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:02:57.757+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO DAGScheduler: Final stage: ResultStage 5 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:02:57.757+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:02:57.758+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:02:57.759+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO DAGScheduler: Submitting ResultStage 5 (PythonRDD[59] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:02:57.773+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 69.8 KiB, free 434.2 MiB)
[2024-05-20T00:02:57.800+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.2 MiB)
[2024-05-20T00:02:57.801+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:02:57.802+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:02:57.802+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (PythonRDD[59] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:02:57.803+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2024-05-20T00:02:57.805+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:02:57.884+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:57 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:02:58.652+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:58 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 841 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:02:58.661+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:58 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2024-05-20T00:02:58.662+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:58 INFO DAGScheduler: ResultStage 5 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.894 s
[2024-05-20T00:02:58.663+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:58 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:02:58.664+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2024-05-20T00:02:58.665+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:58 INFO DAGScheduler: Job 5 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.907779 s
[2024-05-20T00:02:58.762+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/5 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.5.9355e141-af80-4c8c-ba1f-177316109db9.tmp
[2024-05-20T00:02:58.799+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.5.9355e141-af80-4c8c-ba1f-177316109db9.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/5
[2024-05-20T00:02:58.811+0000] {spark_submit.py:571} INFO - 24/05/20 00:02:58 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:02:58.811+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:02:58.812+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:02:58.812+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:02:58.812+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:02:57.446Z",
[2024-05-20T00:02:58.813+0000] {spark_submit.py:571} INFO - "batchId" : 5,
[2024-05-20T00:02:58.813+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:02:58.813+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:02:58.814+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7390983000739099,
[2024-05-20T00:02:58.814+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:02:58.815+0000] {spark_submit.py:571} INFO - "addBatch" : 1085,
[2024-05-20T00:02:58.815+0000] {spark_submit.py:571} INFO - "commitOffsets" : 84,
[2024-05-20T00:02:58.816+0000] {spark_submit.py:571} INFO - "getBatch" : 0,
[2024-05-20T00:02:58.816+0000] {spark_submit.py:571} INFO - "latestOffset" : 5,
[2024-05-20T00:02:58.816+0000] {spark_submit.py:571} INFO - "queryPlanning" : 64,
[2024-05-20T00:02:58.816+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1353,
[2024-05-20T00:02:58.817+0000] {spark_submit.py:571} INFO - "walCommit" : 101
[2024-05-20T00:02:58.817+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:02:58.818+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:02:58.818+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:02:58.818+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:02:58.819+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:02:58.819+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:02:58.819+0000] {spark_submit.py:571} INFO - "0" : 28
[2024-05-20T00:02:58.820+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:58.820+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:02:58.821+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:02:58.821+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:02:58.821+0000] {spark_submit.py:571} INFO - "0" : 29
[2024-05-20T00:02:58.821+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:58.822+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:02:58.822+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:02:58.823+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:02:58.823+0000] {spark_submit.py:571} INFO - "0" : 29
[2024-05-20T00:02:58.823+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:58.823+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:02:58.823+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:02:58.824+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:02:58.824+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7390983000739099,
[2024-05-20T00:02:58.824+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:02:58.824+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:02:58.825+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:02:58.825+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:02:58.825+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:58.825+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:02:58.825+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:02:58.825+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:02:58.825+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:02:58.825+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:02:58.825+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:03:08.411+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:08 INFO BlockManagerInfo: Removed broadcast_4_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:03:08.437+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:08 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:03:08.457+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:08 INFO BlockManagerInfo: Removed broadcast_5_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:03:08.465+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:08 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:03:08.805+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:08 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:03:18.824+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:18 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:03:25.500+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/6 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.6.b3d45c3d-b776-42d7-bba5-5aa5ed3195f0.tmp
[2024-05-20T00:03:25.556+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.6.b3d45c3d-b776-42d7-bba5-5aa5ed3195f0.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/6
[2024-05-20T00:03:25.557+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO MicroBatchExecution: Committed offsets for batch 6. Metadata OffsetSeqMetadata(0,1716163405443,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:03:25.651+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:03:25.654+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:03:25.689+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:03:25.694+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:03:25.751+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:03:25.823+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:03:25.827+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO DAGScheduler: Got job 6 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:03:25.828+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO DAGScheduler: Final stage: ResultStage 6 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:03:25.829+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:03:25.829+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:03:25.831+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO DAGScheduler: Submitting ResultStage 6 (PythonRDD[69] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:03:25.832+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:03:25.844+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:03:25.845+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:03:25.846+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:03:25.847+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (PythonRDD[69] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:03:25.848+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2024-05-20T00:03:25.849+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:03:25.969+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:03:27.014+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:27 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 1148 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:03:27.039+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:27 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2024-05-20T00:03:27.044+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:27 INFO DAGScheduler: ResultStage 6 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 1.197 s
[2024-05-20T00:03:27.050+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:27 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:03:27.051+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
[2024-05-20T00:03:27.051+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:27 INFO DAGScheduler: Job 6 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 1.226780 s
[2024-05-20T00:03:27.167+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/6 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.6.a2111858-f08c-4e09-ab62-27be754b6855.tmp
[2024-05-20T00:03:27.235+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.6.a2111858-f08c-4e09-ab62-27be754b6855.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/6
[2024-05-20T00:03:27.240+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:27 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:03:27.242+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:03:27.243+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:03:27.243+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:03:27.243+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:03:25.441Z",
[2024-05-20T00:03:27.244+0000] {spark_submit.py:571} INFO - "batchId" : 6,
[2024-05-20T00:03:27.244+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:03:27.244+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:03:27.244+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.5574136008918618,
[2024-05-20T00:03:27.245+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:03:27.245+0000] {spark_submit.py:571} INFO - "addBatch" : 1401,
[2024-05-20T00:03:27.245+0000] {spark_submit.py:571} INFO - "commitOffsets" : 168,
[2024-05-20T00:03:27.245+0000] {spark_submit.py:571} INFO - "getBatch" : 0,
[2024-05-20T00:03:27.245+0000] {spark_submit.py:571} INFO - "latestOffset" : 2,
[2024-05-20T00:03:27.246+0000] {spark_submit.py:571} INFO - "queryPlanning" : 96,
[2024-05-20T00:03:27.246+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1794,
[2024-05-20T00:03:27.246+0000] {spark_submit.py:571} INFO - "walCommit" : 114
[2024-05-20T00:03:27.246+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:03:27.246+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:03:27.246+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:03:27.246+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:03:27.247+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:03:27.247+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:03:27.247+0000] {spark_submit.py:571} INFO - "0" : 29
[2024-05-20T00:03:27.247+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:03:27.247+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:03:27.247+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:03:27.247+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:03:27.248+0000] {spark_submit.py:571} INFO - "0" : 30
[2024-05-20T00:03:27.248+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:03:27.248+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:03:27.248+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:03:27.248+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:03:27.248+0000] {spark_submit.py:571} INFO - "0" : 30
[2024-05-20T00:03:27.248+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:03:27.248+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:03:27.249+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:03:27.249+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:03:27.249+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.5574136008918618,
[2024-05-20T00:03:27.249+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:03:27.249+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:03:27.249+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:03:27.249+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:03:27.249+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:03:27.249+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:03:27.250+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:03:27.250+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:03:27.250+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:03:27.250+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:03:27.250+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:03:37.263+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:03:47.266+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:03:48.841+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:48 INFO BlockManagerInfo: Removed broadcast_6_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:03:48.865+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:48 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:03:57.264+0000] {spark_submit.py:571} INFO - 24/05/20 00:03:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:04:07.271+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:04:16.260+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/7 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.7.a9679264-4f45-4837-be60-123472ca5c1a.tmp
[2024-05-20T00:04:16.302+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.7.a9679264-4f45-4837-be60-123472ca5c1a.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/7
[2024-05-20T00:04:16.303+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO MicroBatchExecution: Committed offsets for batch 7. Metadata OffsetSeqMetadata(0,1716163456191,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:04:16.368+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:04:16.373+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:04:16.411+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:04:16.413+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:04:16.448+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:04:16.501+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:04:16.502+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO DAGScheduler: Got job 7 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:04:16.503+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO DAGScheduler: Final stage: ResultStage 7 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:04:16.503+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:04:16.504+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:04:16.504+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO DAGScheduler: Submitting ResultStage 7 (PythonRDD[79] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:04:16.507+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:04:16.514+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:04:16.515+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:04:16.515+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:04:16.516+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (PythonRDD[79] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:04:16.516+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
[2024-05-20T00:04:16.518+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:04:16.580+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:04:17.675+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:17 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 1155 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:04:17.680+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:17 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2024-05-20T00:04:17.681+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:17 INFO DAGScheduler: ResultStage 7 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 1.173 s
[2024-05-20T00:04:17.682+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:17 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:04:17.682+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
[2024-05-20T00:04:17.686+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:17 INFO DAGScheduler: Job 7 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 1.182802 s
[2024-05-20T00:04:17.730+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/7 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.7.a8f0071f-6a7b-4e0e-831a-25ff9244a716.tmp
[2024-05-20T00:04:17.771+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.7.a8f0071f-6a7b-4e0e-831a-25ff9244a716.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/7
[2024-05-20T00:04:17.776+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:17 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:04:17.777+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:04:17.777+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:04:17.777+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:04:17.777+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:04:16.189Z",
[2024-05-20T00:04:17.777+0000] {spark_submit.py:571} INFO - "batchId" : 7,
[2024-05-20T00:04:17.778+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:04:17.778+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:04:17.779+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.6317119393556538,
[2024-05-20T00:04:17.779+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:04:17.779+0000] {spark_submit.py:571} INFO - "addBatch" : 1322,
[2024-05-20T00:04:17.779+0000] {spark_submit.py:571} INFO - "commitOffsets" : 59,
[2024-05-20T00:04:17.779+0000] {spark_submit.py:571} INFO - "getBatch" : 0,
[2024-05-20T00:04:17.780+0000] {spark_submit.py:571} INFO - "latestOffset" : 2,
[2024-05-20T00:04:17.780+0000] {spark_submit.py:571} INFO - "queryPlanning" : 68,
[2024-05-20T00:04:17.780+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1583,
[2024-05-20T00:04:17.780+0000] {spark_submit.py:571} INFO - "walCommit" : 113
[2024-05-20T00:04:17.781+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:04:17.781+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:04:17.781+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:04:17.781+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:04:17.781+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:04:17.782+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:04:17.782+0000] {spark_submit.py:571} INFO - "0" : 30
[2024-05-20T00:04:17.782+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:04:17.782+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:04:17.782+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:04:17.782+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:04:17.783+0000] {spark_submit.py:571} INFO - "0" : 31
[2024-05-20T00:04:17.783+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:04:17.783+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:04:17.783+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:04:17.783+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:04:17.783+0000] {spark_submit.py:571} INFO - "0" : 31
[2024-05-20T00:04:17.783+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:04:17.784+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:04:17.784+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:04:17.784+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:04:17.784+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.6317119393556538,
[2024-05-20T00:04:17.784+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:04:17.784+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:04:17.784+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:04:17.784+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:04:17.785+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:04:17.785+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:04:17.785+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:04:17.785+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:04:17.785+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:04:17.785+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:04:17.785+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:04:27.792+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:04:30.738+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:30 INFO BlockManagerInfo: Removed broadcast_7_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:04:30.777+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:30 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:04:37.792+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:04:47.799+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:04:55.084+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/8 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.8.79342944-d8d8-4403-a053-16b41d917a2c.tmp
[2024-05-20T00:04:55.177+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.8.79342944-d8d8-4403-a053-16b41d917a2c.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/8
[2024-05-20T00:04:55.177+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO MicroBatchExecution: Committed offsets for batch 8. Metadata OffsetSeqMetadata(0,1716163495028,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:04:55.241+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:04:55.244+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:04:55.263+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:04:55.264+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:04:55.306+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:04:55.357+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:04:55.358+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO DAGScheduler: Got job 8 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:04:55.359+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO DAGScheduler: Final stage: ResultStage 8 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:04:55.361+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:04:55.362+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:04:55.362+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO DAGScheduler: Submitting ResultStage 8 (PythonRDD[89] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:04:55.363+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:04:55.389+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:04:55.390+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:04:55.392+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:04:55.393+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (PythonRDD[89] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:04:55.393+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2024-05-20T00:04:55.394+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:04:55.438+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:55 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:04:56.231+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:56 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 828 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:04:56.249+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:56 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2024-05-20T00:04:56.250+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:56 INFO DAGScheduler: ResultStage 8 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.881 s
[2024-05-20T00:04:56.252+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:56 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:04:56.253+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2024-05-20T00:04:56.254+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:56 INFO DAGScheduler: Job 8 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.895531 s
[2024-05-20T00:04:56.316+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/8 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.8.dacd5405-4e36-4178-9cf8-6c4df694712a.tmp
[2024-05-20T00:04:56.368+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.8.dacd5405-4e36-4178-9cf8-6c4df694712a.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/8
[2024-05-20T00:04:56.373+0000] {spark_submit.py:571} INFO - 24/05/20 00:04:56 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:04:56.374+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:04:56.374+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:04:56.375+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:04:56.375+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:04:55.027Z",
[2024-05-20T00:04:56.375+0000] {spark_submit.py:571} INFO - "batchId" : 8,
[2024-05-20T00:04:56.375+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:04:56.375+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:04:56.376+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7457121551081283,
[2024-05-20T00:04:56.376+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:04:56.376+0000] {spark_submit.py:571} INFO - "addBatch" : 1036,
[2024-05-20T00:04:56.376+0000] {spark_submit.py:571} INFO - "commitOffsets" : 81,
[2024-05-20T00:04:56.376+0000] {spark_submit.py:571} INFO - "getBatch" : 0,
[2024-05-20T00:04:56.377+0000] {spark_submit.py:571} INFO - "latestOffset" : 1,
[2024-05-20T00:04:56.377+0000] {spark_submit.py:571} INFO - "queryPlanning" : 65,
[2024-05-20T00:04:56.377+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1341,
[2024-05-20T00:04:56.377+0000] {spark_submit.py:571} INFO - "walCommit" : 150
[2024-05-20T00:04:56.377+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:04:56.377+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:04:56.377+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:04:56.378+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:04:56.378+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:04:56.378+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:04:56.378+0000] {spark_submit.py:571} INFO - "0" : 31
[2024-05-20T00:04:56.378+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:04:56.378+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:04:56.378+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:04:56.378+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:04:56.379+0000] {spark_submit.py:571} INFO - "0" : 32
[2024-05-20T00:04:56.379+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:04:56.379+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:04:56.379+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:04:56.379+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:04:56.379+0000] {spark_submit.py:571} INFO - "0" : 32
[2024-05-20T00:04:56.379+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:04:56.379+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:04:56.379+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:04:56.379+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:04:56.379+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7457121551081283,
[2024-05-20T00:04:56.379+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:04:56.380+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:04:56.380+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:04:56.380+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:04:56.380+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:04:56.380+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:04:56.380+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:04:56.380+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:04:56.380+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:04:56.381+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:04:56.381+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:05:06.378+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:05:13.578+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:13 INFO BlockManagerInfo: Removed broadcast_8_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:05:13.615+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:13 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:05:16.384+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:05:18.735+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/9 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.9.a445eb8d-287a-40d0-92bf-453ba0afffe6.tmp
[2024-05-20T00:05:18.765+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.9.a445eb8d-287a-40d0-92bf-453ba0afffe6.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/9
[2024-05-20T00:05:18.766+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:18 INFO MicroBatchExecution: Committed offsets for batch 9. Metadata OffsetSeqMetadata(0,1716163518691,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:05:18.839+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:18 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:05:18.843+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:18 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:05:18.870+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:18 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:05:18.871+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:18 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:05:18.924+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:05:19.018+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:05:19.020+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO DAGScheduler: Got job 9 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:05:19.020+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO DAGScheduler: Final stage: ResultStage 9 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:05:19.021+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:05:19.021+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:05:19.021+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO DAGScheduler: Submitting ResultStage 9 (PythonRDD[99] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:05:19.023+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:05:19.041+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:05:19.042+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:05:19.043+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:05:19.044+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (PythonRDD[99] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:05:19.044+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2024-05-20T00:05:19.046+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:05:19.111+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:05:19.929+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 879 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:05:19.934+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2024-05-20T00:05:19.935+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO DAGScheduler: ResultStage 9 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.912 s
[2024-05-20T00:05:19.937+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:05:19.938+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
[2024-05-20T00:05:19.938+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:19 INFO DAGScheduler: Job 9 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.920240 s
[2024-05-20T00:05:20.003+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/9 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.9.4051010b-d36f-42bd-940c-cf588a4210e0.tmp
[2024-05-20T00:05:20.045+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.9.4051010b-d36f-42bd-940c-cf588a4210e0.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/9
[2024-05-20T00:05:20.062+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:20 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:05:20.064+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:05:20.064+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:05:20.064+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:05:20.065+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:05:18.687Z",
[2024-05-20T00:05:20.065+0000] {spark_submit.py:571} INFO - "batchId" : 9,
[2024-05-20T00:05:20.065+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:05:20.065+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 62.5,
[2024-05-20T00:05:20.066+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7358351729212657,
[2024-05-20T00:05:20.066+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:05:20.066+0000] {spark_submit.py:571} INFO - "addBatch" : 1104,
[2024-05-20T00:05:20.066+0000] {spark_submit.py:571} INFO - "commitOffsets" : 88,
[2024-05-20T00:05:20.067+0000] {spark_submit.py:571} INFO - "getBatch" : 1,
[2024-05-20T00:05:20.067+0000] {spark_submit.py:571} INFO - "latestOffset" : 3,
[2024-05-20T00:05:20.067+0000] {spark_submit.py:571} INFO - "queryPlanning" : 76,
[2024-05-20T00:05:20.067+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1359,
[2024-05-20T00:05:20.067+0000] {spark_submit.py:571} INFO - "walCommit" : 75
[2024-05-20T00:05:20.067+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:05:20.067+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:05:20.067+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:05:20.068+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:05:20.068+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:05:20.068+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:05:20.068+0000] {spark_submit.py:571} INFO - "0" : 32
[2024-05-20T00:05:20.068+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:05:20.068+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:05:20.068+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:05:20.069+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:05:20.069+0000] {spark_submit.py:571} INFO - "0" : 33
[2024-05-20T00:05:20.069+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:05:20.069+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:05:20.069+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:05:20.069+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:05:20.070+0000] {spark_submit.py:571} INFO - "0" : 33
[2024-05-20T00:05:20.070+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:05:20.070+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:05:20.070+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:05:20.070+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 62.5,
[2024-05-20T00:05:20.070+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7358351729212657,
[2024-05-20T00:05:20.070+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:05:20.070+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:05:20.071+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:05:20.071+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:05:20.071+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:05:20.071+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:05:20.071+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:05:20.071+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:05:20.071+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:05:20.071+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:05:20.071+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:05:29.264+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:29 INFO NetworkClient: [AdminClient clientId=adminclient-1] Node -1 disconnected.
[2024-05-20T00:05:30.067+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:05:40.093+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:05:47.196+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/10 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.10.fdca53ab-3179-45e4-8519-82846aaec045.tmp
[2024-05-20T00:05:47.229+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.10.fdca53ab-3179-45e4-8519-82846aaec045.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/10
[2024-05-20T00:05:47.230+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO MicroBatchExecution: Committed offsets for batch 10. Metadata OffsetSeqMetadata(0,1716163547141,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:05:47.292+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:05:47.294+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:05:47.311+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:05:47.313+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:05:47.369+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:05:47.425+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:05:47.426+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO DAGScheduler: Got job 10 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:05:47.426+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO DAGScheduler: Final stage: ResultStage 10 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:05:47.427+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:05:47.429+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:05:47.433+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[109] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:05:47.433+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 69.8 KiB, free 434.2 MiB)
[2024-05-20T00:05:47.455+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.2 MiB)
[2024-05-20T00:05:47.457+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:05:47.458+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:05:47.459+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (PythonRDD[109] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:05:47.459+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
[2024-05-20T00:05:47.461+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:05:47.512+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:47 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:05:48.318+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:48 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 854 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:05:48.328+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:48 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
[2024-05-20T00:05:48.330+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:48 INFO DAGScheduler: ResultStage 10 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.892 s
[2024-05-20T00:05:48.333+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:48 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:05:48.334+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
[2024-05-20T00:05:48.335+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:48 INFO DAGScheduler: Job 10 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.909177 s
[2024-05-20T00:05:48.393+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:48 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/10 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.10.30de6ff6-3aa4-407e-8249-d542fcb4eb75.tmp
[2024-05-20T00:05:48.445+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:48 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.10.30de6ff6-3aa4-407e-8249-d542fcb4eb75.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/10
[2024-05-20T00:05:48.452+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:48 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:05:48.453+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:05:48.453+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:05:48.454+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:05:48.454+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:05:47.138Z",
[2024-05-20T00:05:48.454+0000] {spark_submit.py:571} INFO - "batchId" : 10,
[2024-05-20T00:05:48.455+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:05:48.455+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 66.66666666666667,
[2024-05-20T00:05:48.455+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.764525993883792,
[2024-05-20T00:05:48.456+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:05:48.456+0000] {spark_submit.py:571} INFO - "addBatch" : 1058,
[2024-05-20T00:05:48.456+0000] {spark_submit.py:571} INFO - "commitOffsets" : 84,
[2024-05-20T00:05:48.457+0000] {spark_submit.py:571} INFO - "getBatch" : 1,
[2024-05-20T00:05:48.458+0000] {spark_submit.py:571} INFO - "latestOffset" : 3,
[2024-05-20T00:05:48.458+0000] {spark_submit.py:571} INFO - "queryPlanning" : 64,
[2024-05-20T00:05:48.460+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1308,
[2024-05-20T00:05:48.460+0000] {spark_submit.py:571} INFO - "walCommit" : 88
[2024-05-20T00:05:48.460+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:05:48.461+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:05:48.461+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:05:48.461+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:05:48.462+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:05:48.462+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:05:48.462+0000] {spark_submit.py:571} INFO - "0" : 33
[2024-05-20T00:05:48.463+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:05:48.464+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:05:48.464+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:05:48.464+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:05:48.464+0000] {spark_submit.py:571} INFO - "0" : 34
[2024-05-20T00:05:48.465+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:05:48.465+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:05:48.465+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:05:48.466+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:05:48.466+0000] {spark_submit.py:571} INFO - "0" : 34
[2024-05-20T00:05:48.466+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:05:48.466+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:05:48.466+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:05:48.466+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 66.66666666666667,
[2024-05-20T00:05:48.467+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.764525993883792,
[2024-05-20T00:05:48.467+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:05:48.467+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:05:48.467+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:05:48.467+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:05:48.467+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:05:48.467+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:05:48.468+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:05:48.468+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:05:48.468+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:05:48.469+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:05:48.469+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:05:50.284+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:50 INFO BlockManagerInfo: Removed broadcast_10_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:05:50.321+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:50 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:05:50.329+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:50 INFO BlockManagerInfo: Removed broadcast_9_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:05:50.333+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:50 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:05:58.475+0000] {spark_submit.py:571} INFO - 24/05/20 00:05:58 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:06:08.494+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:08 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:06:16.156+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/11 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.11.2c808b54-a67c-45b8-84ce-3dfcab0e1e9d.tmp
[2024-05-20T00:06:16.201+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.11.2c808b54-a67c-45b8-84ce-3dfcab0e1e9d.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/11
[2024-05-20T00:06:16.202+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO MicroBatchExecution: Committed offsets for batch 11. Metadata OffsetSeqMetadata(0,1716163576105,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:06:16.258+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:06:16.261+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:06:16.285+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:06:16.286+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:06:16.315+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:06:16.357+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:06:16.359+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO DAGScheduler: Got job 11 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:06:16.363+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO DAGScheduler: Final stage: ResultStage 11 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:06:16.363+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:06:16.363+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:06:16.364+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO DAGScheduler: Submitting ResultStage 11 (PythonRDD[119] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:06:16.364+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:06:16.374+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:06:16.377+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:06:16.378+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:06:16.382+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (PythonRDD[119] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:06:16.383+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2024-05-20T00:06:16.394+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:06:16.433+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:16 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:06:17.323+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:17 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 926 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:06:17.332+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:17 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2024-05-20T00:06:17.333+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:17 INFO DAGScheduler: ResultStage 11 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.968 s
[2024-05-20T00:06:17.338+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:17 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:06:17.341+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
[2024-05-20T00:06:17.346+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:17 INFO DAGScheduler: Job 11 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.986748 s
[2024-05-20T00:06:17.439+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/11 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.11.6af36886-2ce5-45ad-bd72-2a3e42753ca6.tmp
[2024-05-20T00:06:17.499+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.11.6af36886-2ce5-45ad-bd72-2a3e42753ca6.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/11
[2024-05-20T00:06:17.503+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:17 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:06:17.503+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:06:17.503+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:06:17.504+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:06:17.504+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:06:16.101Z",
[2024-05-20T00:06:17.504+0000] {spark_submit.py:571} INFO - "batchId" : 11,
[2024-05-20T00:06:17.504+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:06:17.504+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 66.66666666666667,
[2024-05-20T00:06:17.505+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.715307582260372,
[2024-05-20T00:06:17.505+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:06:17.505+0000] {spark_submit.py:571} INFO - "addBatch" : 1133,
[2024-05-20T00:06:17.506+0000] {spark_submit.py:571} INFO - "commitOffsets" : 99,
[2024-05-20T00:06:17.506+0000] {spark_submit.py:571} INFO - "getBatch" : 0,
[2024-05-20T00:06:17.506+0000] {spark_submit.py:571} INFO - "latestOffset" : 4,
[2024-05-20T00:06:17.506+0000] {spark_submit.py:571} INFO - "queryPlanning" : 59,
[2024-05-20T00:06:17.506+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1398,
[2024-05-20T00:06:17.506+0000] {spark_submit.py:571} INFO - "walCommit" : 97
[2024-05-20T00:06:17.506+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:06:17.507+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:06:17.507+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:06:17.507+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:06:17.507+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:06:17.507+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:06:17.507+0000] {spark_submit.py:571} INFO - "0" : 34
[2024-05-20T00:06:17.507+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:06:17.507+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:06:17.508+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:06:17.508+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:06:17.508+0000] {spark_submit.py:571} INFO - "0" : 35
[2024-05-20T00:06:17.508+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:06:17.508+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:06:17.508+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:06:17.508+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:06:17.508+0000] {spark_submit.py:571} INFO - "0" : 35
[2024-05-20T00:06:17.508+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:06:17.509+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:06:17.509+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:06:17.509+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 66.66666666666667,
[2024-05-20T00:06:17.509+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.715307582260372,
[2024-05-20T00:06:17.509+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:06:17.509+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:06:17.509+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:06:17.509+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:06:17.510+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:06:17.510+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:06:17.510+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:06:17.510+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:06:17.510+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:06:17.510+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:06:17.510+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:06:27.518+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:06:32.384+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:32 INFO BlockManagerInfo: Removed broadcast_11_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:06:32.447+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:32 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:06:37.514+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:06:47.530+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:06:50.227+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/12 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.12.134f62ed-ef67-40b6-8ce3-d4f8dd7f6aca.tmp
[2024-05-20T00:06:50.272+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.12.134f62ed-ef67-40b6-8ce3-d4f8dd7f6aca.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/12
[2024-05-20T00:06:50.274+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO MicroBatchExecution: Committed offsets for batch 12. Metadata OffsetSeqMetadata(0,1716163610189,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:06:50.327+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:06:50.334+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:06:50.369+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:06:50.372+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:06:50.412+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:06:50.507+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:06:50.509+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO DAGScheduler: Got job 12 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:06:50.510+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO DAGScheduler: Final stage: ResultStage 12 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:06:50.510+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:06:50.510+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:06:50.511+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO DAGScheduler: Submitting ResultStage 12 (PythonRDD[129] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:06:50.513+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:06:50.518+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:06:50.519+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:06:50.519+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:06:50.520+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (PythonRDD[129] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:06:50.520+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2024-05-20T00:06:50.522+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:06:50.619+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:50 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:06:51.473+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:51 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 949 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:06:51.479+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:51 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2024-05-20T00:06:51.479+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:51 INFO DAGScheduler: ResultStage 12 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.966 s
[2024-05-20T00:06:51.482+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:51 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:06:51.483+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
[2024-05-20T00:06:51.484+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:51 INFO DAGScheduler: Job 12 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.972627 s
[2024-05-20T00:06:51.564+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:51 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/12 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.12.021531e3-134e-4306-b1ea-96248f491753.tmp
[2024-05-20T00:06:51.590+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:51 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.12.021531e3-134e-4306-b1ea-96248f491753.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/12
[2024-05-20T00:06:51.594+0000] {spark_submit.py:571} INFO - 24/05/20 00:06:51 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:06:51.594+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:06:51.594+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:06:51.594+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:06:51.595+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:06:50.187Z",
[2024-05-20T00:06:51.595+0000] {spark_submit.py:571} INFO - "batchId" : 12,
[2024-05-20T00:06:51.595+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:06:51.595+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 71.42857142857143,
[2024-05-20T00:06:51.596+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7127583749109052,
[2024-05-20T00:06:51.596+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:06:51.596+0000] {spark_submit.py:571} INFO - "addBatch" : 1156,
[2024-05-20T00:06:51.596+0000] {spark_submit.py:571} INFO - "commitOffsets" : 89,
[2024-05-20T00:06:51.596+0000] {spark_submit.py:571} INFO - "getBatch" : 0,
[2024-05-20T00:06:51.596+0000] {spark_submit.py:571} INFO - "latestOffset" : 2,
[2024-05-20T00:06:51.596+0000] {spark_submit.py:571} INFO - "queryPlanning" : 64,
[2024-05-20T00:06:51.597+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1403,
[2024-05-20T00:06:51.597+0000] {spark_submit.py:571} INFO - "walCommit" : 84
[2024-05-20T00:06:51.597+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:06:51.597+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:06:51.597+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:06:51.597+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:06:51.597+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:06:51.598+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:06:51.598+0000] {spark_submit.py:571} INFO - "0" : 35
[2024-05-20T00:06:51.598+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:06:51.598+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:06:51.598+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:06:51.598+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:06:51.598+0000] {spark_submit.py:571} INFO - "0" : 36
[2024-05-20T00:06:51.599+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:06:51.599+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:06:51.599+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:06:51.599+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:06:51.599+0000] {spark_submit.py:571} INFO - "0" : 36
[2024-05-20T00:06:51.599+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:06:51.599+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:06:51.599+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:06:51.599+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 71.42857142857143,
[2024-05-20T00:06:51.600+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7127583749109052,
[2024-05-20T00:06:51.600+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:06:51.600+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:06:51.600+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:06:51.600+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:06:51.600+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:06:51.600+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:06:51.600+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:06:51.600+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:06:51.601+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:06:51.601+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:06:51.601+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:07:01.626+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:01 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:07:11.615+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:11 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:07:15.027+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:15 INFO BlockManagerInfo: Removed broadcast_12_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:07:15.032+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:15 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:07:21.610+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:21 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:07:23.923+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/13 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.13.82e1984d-b3e8-4eab-9d6a-d47e2fefaaac.tmp
[2024-05-20T00:07:23.962+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.13.82e1984d-b3e8-4eab-9d6a-d47e2fefaaac.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/13
[2024-05-20T00:07:23.963+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:23 INFO MicroBatchExecution: Committed offsets for batch 13. Metadata OffsetSeqMetadata(0,1716163643857,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:07:24.037+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:07:24.042+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:07:24.082+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:07:24.083+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:07:24.154+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:07:24.190+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:07:24.192+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO DAGScheduler: Got job 13 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:07:24.192+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO DAGScheduler: Final stage: ResultStage 13 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:07:24.192+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:07:24.192+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:07:24.193+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO DAGScheduler: Submitting ResultStage 13 (PythonRDD[139] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:07:24.196+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:07:24.215+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:07:24.219+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:07:24.220+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:07:24.220+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (PythonRDD[139] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:07:24.221+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
[2024-05-20T00:07:24.223+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:07:24.304+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:24 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:07:25.017+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:25 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 794 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:07:25.020+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:25 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2024-05-20T00:07:25.025+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:25 INFO DAGScheduler: ResultStage 13 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.828 s
[2024-05-20T00:07:25.027+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:25 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:07:25.028+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
[2024-05-20T00:07:25.028+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:25 INFO DAGScheduler: Job 13 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.837315 s
[2024-05-20T00:07:25.084+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/13 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.13.5ae83be2-2c6e-4551-bca5-40c5291fb53a.tmp
[2024-05-20T00:07:25.148+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.13.5ae83be2-2c6e-4551-bca5-40c5291fb53a.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/13
[2024-05-20T00:07:25.152+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:25 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:07:25.153+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:07:25.153+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:07:25.154+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:07:25.154+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:07:23.855Z",
[2024-05-20T00:07:25.154+0000] {spark_submit.py:571} INFO - "batchId" : 13,
[2024-05-20T00:07:25.154+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:07:25.154+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 62.5,
[2024-05-20T00:07:25.154+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7733952049497294,
[2024-05-20T00:07:25.154+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:07:25.154+0000] {spark_submit.py:571} INFO - "addBatch" : 989,
[2024-05-20T00:07:25.155+0000] {spark_submit.py:571} INFO - "commitOffsets" : 91,
[2024-05-20T00:07:25.155+0000] {spark_submit.py:571} INFO - "getBatch" : 0,
[2024-05-20T00:07:25.155+0000] {spark_submit.py:571} INFO - "latestOffset" : 2,
[2024-05-20T00:07:25.155+0000] {spark_submit.py:571} INFO - "queryPlanning" : 80,
[2024-05-20T00:07:25.155+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1293,
[2024-05-20T00:07:25.155+0000] {spark_submit.py:571} INFO - "walCommit" : 107
[2024-05-20T00:07:25.155+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:07:25.155+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:07:25.155+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:07:25.156+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:07:25.156+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:07:25.156+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:07:25.156+0000] {spark_submit.py:571} INFO - "0" : 36
[2024-05-20T00:07:25.156+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:07:25.160+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:07:25.160+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:07:25.160+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:07:25.161+0000] {spark_submit.py:571} INFO - "0" : 37
[2024-05-20T00:07:25.161+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:07:25.161+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:07:25.161+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:07:25.161+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:07:25.161+0000] {spark_submit.py:571} INFO - "0" : 37
[2024-05-20T00:07:25.161+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:07:25.161+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:07:25.162+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:07:25.162+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 62.5,
[2024-05-20T00:07:25.162+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7733952049497294,
[2024-05-20T00:07:25.162+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:07:25.162+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:07:25.162+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:07:25.162+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:07:25.163+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:07:25.163+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:07:25.163+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:07:25.163+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:07:25.163+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:07:25.163+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:07:25.163+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:07:35.161+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:07:45.170+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:07:53.402+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/14 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.14.9d1d7b48-c7ca-44a8-b3d7-fbd7b579d6d3.tmp
[2024-05-20T00:07:53.448+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.14.9d1d7b48-c7ca-44a8-b3d7-fbd7b579d6d3.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/14
[2024-05-20T00:07:53.450+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO MicroBatchExecution: Committed offsets for batch 14. Metadata OffsetSeqMetadata(0,1716163673345,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:07:53.506+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:07:53.510+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:07:53.545+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:07:53.546+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:07:53.618+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO BlockManagerInfo: Removed broadcast_13_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:07:53.641+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:07:53.654+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:07:53.703+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:07:53.705+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO DAGScheduler: Got job 14 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:07:53.707+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO DAGScheduler: Final stage: ResultStage 14 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:07:53.708+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:07:53.708+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:07:53.708+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO DAGScheduler: Submitting ResultStage 14 (PythonRDD[149] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:07:53.710+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:07:53.716+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:07:53.716+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:07:53.717+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:07:53.717+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (PythonRDD[149] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:07:53.718+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2024-05-20T00:07:53.719+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:07:53.767+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:53 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:07:54.607+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:54 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 885 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:07:54.613+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:54 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2024-05-20T00:07:54.615+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:54 INFO DAGScheduler: ResultStage 14 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.903 s
[2024-05-20T00:07:54.618+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:54 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:07:54.619+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
[2024-05-20T00:07:54.619+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:54 INFO DAGScheduler: Job 14 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.909977 s
[2024-05-20T00:07:54.694+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/14 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.14.0d9ff6de-96eb-45b9-a247-a5b574d758ba.tmp
[2024-05-20T00:07:54.754+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.14.0d9ff6de-96eb-45b9-a247-a5b574d758ba.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/14
[2024-05-20T00:07:54.759+0000] {spark_submit.py:571} INFO - 24/05/20 00:07:54 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:07:54.760+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:07:54.760+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:07:54.761+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:07:54.761+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:07:53.343Z",
[2024-05-20T00:07:54.762+0000] {spark_submit.py:571} INFO - "batchId" : 14,
[2024-05-20T00:07:54.762+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:07:54.762+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:07:54.763+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7087172218284904,
[2024-05-20T00:07:54.763+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:07:54.763+0000] {spark_submit.py:571} INFO - "addBatch" : 1107,
[2024-05-20T00:07:54.764+0000] {spark_submit.py:571} INFO - "commitOffsets" : 127,
[2024-05-20T00:07:54.764+0000] {spark_submit.py:571} INFO - "getBatch" : 1,
[2024-05-20T00:07:54.764+0000] {spark_submit.py:571} INFO - "latestOffset" : 2,
[2024-05-20T00:07:54.764+0000] {spark_submit.py:571} INFO - "queryPlanning" : 56,
[2024-05-20T00:07:54.764+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1411,
[2024-05-20T00:07:54.765+0000] {spark_submit.py:571} INFO - "walCommit" : 108
[2024-05-20T00:07:54.765+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:07:54.765+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:07:54.765+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:07:54.766+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:07:54.766+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:07:54.766+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:07:54.766+0000] {spark_submit.py:571} INFO - "0" : 37
[2024-05-20T00:07:54.766+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:07:54.768+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:07:54.768+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:07:54.768+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:07:54.769+0000] {spark_submit.py:571} INFO - "0" : 38
[2024-05-20T00:07:54.769+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:07:54.769+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:07:54.769+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:07:54.769+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:07:54.770+0000] {spark_submit.py:571} INFO - "0" : 38
[2024-05-20T00:07:54.770+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:07:54.770+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:07:54.770+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:07:54.770+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:07:54.770+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7087172218284904,
[2024-05-20T00:07:54.771+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:07:54.771+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:07:54.771+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:07:54.771+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:07:54.771+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:07:54.771+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:07:54.772+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:07:54.772+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:07:54.772+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:07:54.772+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:07:54.772+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:08:04.791+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:04 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:08:14.813+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:14 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:08:21.118+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/15 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.15.cb2c3b32-4d9e-4889-b958-d3a8c54309bb.tmp
[2024-05-20T00:08:21.191+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.15.cb2c3b32-4d9e-4889-b958-d3a8c54309bb.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/15
[2024-05-20T00:08:21.192+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO MicroBatchExecution: Committed offsets for batch 15. Metadata OffsetSeqMetadata(0,1716163701039,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:08:21.278+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:08:21.290+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:08:21.335+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:08:21.336+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:08:21.411+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:08:21.493+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:08:21.500+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO DAGScheduler: Got job 15 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:08:21.501+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO DAGScheduler: Final stage: ResultStage 15 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:08:21.502+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:08:21.503+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:08:21.503+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO DAGScheduler: Submitting ResultStage 15 (PythonRDD[159] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:08:21.508+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 69.8 KiB, free 434.2 MiB)
[2024-05-20T00:08:21.523+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.2 MiB)
[2024-05-20T00:08:21.525+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:08:21.529+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:08:21.529+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (PythonRDD[159] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:08:21.530+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2024-05-20T00:08:21.539+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:08:21.647+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:21 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:08:22.685+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:22 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 1146 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:08:22.693+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:22 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2024-05-20T00:08:22.693+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:22 INFO DAGScheduler: ResultStage 15 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 1.184 s
[2024-05-20T00:08:22.696+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:22 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:08:22.696+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
[2024-05-20T00:08:22.706+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:22 INFO DAGScheduler: Job 15 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 1.198862 s
[2024-05-20T00:08:22.789+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/15 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.15.cc4e4c66-b78a-4b77-8c6c-1dbf7009c6b2.tmp
[2024-05-20T00:08:22.837+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.15.cc4e4c66-b78a-4b77-8c6c-1dbf7009c6b2.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/15
[2024-05-20T00:08:22.842+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:22 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:08:22.842+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:08:22.842+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:08:22.842+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:08:22.843+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:08:21.037Z",
[2024-05-20T00:08:22.843+0000] {spark_submit.py:571} INFO - "batchId" : 15,
[2024-05-20T00:08:22.843+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:08:22.843+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:08:22.843+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.5555555555555556,
[2024-05-20T00:08:22.843+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:08:22.844+0000] {spark_submit.py:571} INFO - "addBatch" : 1412,
[2024-05-20T00:08:22.844+0000] {spark_submit.py:571} INFO - "commitOffsets" : 99,
[2024-05-20T00:08:22.844+0000] {spark_submit.py:571} INFO - "getBatch" : 1,
[2024-05-20T00:08:22.844+0000] {spark_submit.py:571} INFO - "latestOffset" : 2,
[2024-05-20T00:08:22.844+0000] {spark_submit.py:571} INFO - "queryPlanning" : 101,
[2024-05-20T00:08:22.844+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1800,
[2024-05-20T00:08:22.844+0000] {spark_submit.py:571} INFO - "walCommit" : 154
[2024-05-20T00:08:22.845+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:08:22.845+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:08:22.845+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:08:22.845+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:08:22.845+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:08:22.845+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:08:22.845+0000] {spark_submit.py:571} INFO - "0" : 38
[2024-05-20T00:08:22.846+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:08:22.846+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:08:22.846+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:08:22.846+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:08:22.846+0000] {spark_submit.py:571} INFO - "0" : 39
[2024-05-20T00:08:22.846+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:08:22.846+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:08:22.846+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:08:22.846+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:08:22.847+0000] {spark_submit.py:571} INFO - "0" : 39
[2024-05-20T00:08:22.847+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:08:22.847+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:08:22.847+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:08:22.847+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:08:22.847+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.5555555555555556,
[2024-05-20T00:08:22.847+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:08:22.847+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:08:22.847+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:08:22.848+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:08:22.848+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:08:22.848+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:08:22.848+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:08:22.848+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:08:22.848+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:08:22.848+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:08:22.848+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:08:32.864+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:08:34.941+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:34 INFO BlockManagerInfo: Removed broadcast_15_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:08:34.956+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:34 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:08:34.965+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:34 INFO BlockManagerInfo: Removed broadcast_14_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:08:34.966+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:34 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:08:42.881+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:08:48.963+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:48 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/16 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.16.63cf07ec-6e2f-4cd5-b043-9c5ac611401a.tmp
[2024-05-20T00:08:49.004+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.16.63cf07ec-6e2f-4cd5-b043-9c5ac611401a.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/16
[2024-05-20T00:08:49.004+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO MicroBatchExecution: Committed offsets for batch 16. Metadata OffsetSeqMetadata(0,1716163728903,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:08:49.070+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:08:49.073+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:08:49.093+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:08:49.094+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:08:49.132+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:08:49.194+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:08:49.196+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO DAGScheduler: Got job 16 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:08:49.197+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO DAGScheduler: Final stage: ResultStage 16 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:08:49.200+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:08:49.201+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:08:49.201+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO DAGScheduler: Submitting ResultStage 16 (PythonRDD[169] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:08:49.202+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:08:49.210+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:08:49.211+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:08:49.213+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:08:49.213+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (PythonRDD[169] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:08:49.214+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
[2024-05-20T00:08:49.214+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:08:49.285+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:49 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:08:50.081+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:50 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 860 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:08:50.097+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:50 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2024-05-20T00:08:50.100+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:50 INFO DAGScheduler: ResultStage 16 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.892 s
[2024-05-20T00:08:50.103+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:50 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:08:50.104+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
[2024-05-20T00:08:50.112+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:50 INFO DAGScheduler: Job 16 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.916857 s
[2024-05-20T00:08:50.157+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:50 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/16 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.16.ce98e0b9-bb4c-4f8b-99da-87c29fea0b33.tmp
[2024-05-20T00:08:50.199+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:50 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.16.ce98e0b9-bb4c-4f8b-99da-87c29fea0b33.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/16
[2024-05-20T00:08:50.210+0000] {spark_submit.py:571} INFO - 24/05/20 00:08:50 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:08:50.211+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:08:50.211+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:08:50.211+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:08:50.211+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:08:48.901Z",
[2024-05-20T00:08:50.212+0000] {spark_submit.py:571} INFO - "batchId" : 16,
[2024-05-20T00:08:50.212+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:08:50.212+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 71.42857142857143,
[2024-05-20T00:08:50.213+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7704160246533127,
[2024-05-20T00:08:50.213+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:08:50.214+0000] {spark_submit.py:571} INFO - "addBatch" : 1055,
[2024-05-20T00:08:50.214+0000] {spark_submit.py:571} INFO - "commitOffsets" : 66,
[2024-05-20T00:08:50.214+0000] {spark_submit.py:571} INFO - "getBatch" : 1,
[2024-05-20T00:08:50.214+0000] {spark_submit.py:571} INFO - "latestOffset" : 2,
[2024-05-20T00:08:50.214+0000] {spark_submit.py:571} INFO - "queryPlanning" : 68,
[2024-05-20T00:08:50.214+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1298,
[2024-05-20T00:08:50.214+0000] {spark_submit.py:571} INFO - "walCommit" : 102
[2024-05-20T00:08:50.215+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:08:50.215+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:08:50.215+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:08:50.215+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:08:50.215+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:08:50.215+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:08:50.215+0000] {spark_submit.py:571} INFO - "0" : 39
[2024-05-20T00:08:50.215+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:08:50.216+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:08:50.216+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:08:50.216+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:08:50.216+0000] {spark_submit.py:571} INFO - "0" : 40
[2024-05-20T00:08:50.216+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:08:50.216+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:08:50.216+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:08:50.216+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:08:50.216+0000] {spark_submit.py:571} INFO - "0" : 40
[2024-05-20T00:08:50.217+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:08:50.217+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:08:50.217+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:08:50.217+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 71.42857142857143,
[2024-05-20T00:08:50.217+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.7704160246533127,
[2024-05-20T00:08:50.217+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:08:50.217+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:08:50.217+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:08:50.218+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:08:50.218+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:08:50.218+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:08:50.218+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:08:50.218+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:08:50.218+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:08:50.218+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:08:50.218+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:09:00.229+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:09:10.246+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:09:17.004+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:17 INFO BlockManagerInfo: Removed broadcast_16_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:09:17.055+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:17 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:09:20.247+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:09:28.822+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/17 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.17.ee36e0be-7634-4888-94b9-eaab04343528.tmp
[2024-05-20T00:09:28.854+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.17.ee36e0be-7634-4888-94b9-eaab04343528.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/17
[2024-05-20T00:09:28.854+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:28 INFO MicroBatchExecution: Committed offsets for batch 17. Metadata OffsetSeqMetadata(0,1716163768767,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:09:28.922+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:28 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:09:28.927+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:28 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:09:28.950+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:28 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:09:28.955+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:28 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:09:29.005+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:09:29.058+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:09:29.060+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO DAGScheduler: Got job 17 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:09:29.061+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO DAGScheduler: Final stage: ResultStage 17 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:09:29.061+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:09:29.061+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:09:29.062+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO DAGScheduler: Submitting ResultStage 17 (PythonRDD[179] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:09:29.065+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:09:29.071+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:09:29.071+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:09:29.072+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:09:29.072+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (PythonRDD[179] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:09:29.073+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
[2024-05-20T00:09:29.074+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:09:29.142+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:09:29.867+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 790 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:09:29.879+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool
[2024-05-20T00:09:29.880+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO DAGScheduler: ResultStage 17 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.806 s
[2024-05-20T00:09:29.881+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:09:29.881+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
[2024-05-20T00:09:29.882+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO DAGScheduler: Job 17 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.815540 s
[2024-05-20T00:09:29.934+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/17 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.17.a9b6b566-7c1b-425a-a957-edfc259bef45.tmp
[2024-05-20T00:09:29.978+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.17.a9b6b566-7c1b-425a-a957-edfc259bef45.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/17
[2024-05-20T00:09:29.982+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:29 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:09:29.983+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:09:29.983+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:09:29.983+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:09:29.983+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:09:28.765Z",
[2024-05-20T00:09:29.984+0000] {spark_submit.py:571} INFO - "batchId" : 17,
[2024-05-20T00:09:29.984+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:09:29.984+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 83.33333333333333,
[2024-05-20T00:09:29.984+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.8237232289950577,
[2024-05-20T00:09:29.984+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:09:29.985+0000] {spark_submit.py:571} INFO - "addBatch" : 960,
[2024-05-20T00:09:29.985+0000] {spark_submit.py:571} INFO - "commitOffsets" : 83,
[2024-05-20T00:09:29.985+0000] {spark_submit.py:571} INFO - "getBatch" : 2,
[2024-05-20T00:09:29.985+0000] {spark_submit.py:571} INFO - "latestOffset" : 2,
[2024-05-20T00:09:29.985+0000] {spark_submit.py:571} INFO - "queryPlanning" : 72,
[2024-05-20T00:09:29.986+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1214,
[2024-05-20T00:09:29.986+0000] {spark_submit.py:571} INFO - "walCommit" : 88
[2024-05-20T00:09:29.987+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:09:29.987+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:09:29.987+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:09:29.987+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:09:29.987+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:09:29.987+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:09:29.987+0000] {spark_submit.py:571} INFO - "0" : 40
[2024-05-20T00:09:29.988+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:09:29.988+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:09:29.988+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:09:29.988+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:09:29.988+0000] {spark_submit.py:571} INFO - "0" : 41
[2024-05-20T00:09:29.988+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:09:29.988+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:09:29.988+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:09:29.989+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:09:29.989+0000] {spark_submit.py:571} INFO - "0" : 41
[2024-05-20T00:09:29.989+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:09:29.989+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:09:29.989+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:09:29.989+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 83.33333333333333,
[2024-05-20T00:09:29.989+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.8237232289950577,
[2024-05-20T00:09:29.989+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:09:29.989+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:09:29.990+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:09:29.990+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:09:29.990+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:09:29.990+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:09:29.990+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:09:29.990+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:09:29.990+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:09:29.990+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:09:29.991+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:09:40.000+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:39 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:09:50.005+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:49 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:09:56.243+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/18 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.18.6d6d5564-a96a-4856-9a5b-9359d0fdf1d7.tmp
[2024-05-20T00:09:56.272+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.18.6d6d5564-a96a-4856-9a5b-9359d0fdf1d7.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/18
[2024-05-20T00:09:56.275+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO MicroBatchExecution: Committed offsets for batch 18. Metadata OffsetSeqMetadata(0,1716163796201,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:09:56.322+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:09:56.325+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:09:56.358+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:09:56.359+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:09:56.405+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO BlockManagerInfo: Removed broadcast_17_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:09:56.457+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:09:56.458+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:09:56.510+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:09:56.511+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO DAGScheduler: Got job 18 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:09:56.511+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO DAGScheduler: Final stage: ResultStage 18 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:09:56.512+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:09:56.512+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:09:56.512+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO DAGScheduler: Submitting ResultStage 18 (PythonRDD[189] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:09:56.515+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:09:56.520+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:09:56.521+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:09:56.521+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:09:56.521+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (PythonRDD[189] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:09:56.521+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2024-05-20T00:09:56.523+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:09:56.566+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:56 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:09:57.520+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:57 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 994 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:09:57.526+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:57 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2024-05-20T00:09:57.527+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:57 INFO DAGScheduler: ResultStage 18 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 1.009 s
[2024-05-20T00:09:57.528+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:57 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:09:57.529+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
[2024-05-20T00:09:57.529+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:57 INFO DAGScheduler: Job 18 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 1.016384 s
[2024-05-20T00:09:57.617+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/18 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.18.ddb7251d-3373-444c-8ef9-9dae6e0ca5ee.tmp
[2024-05-20T00:09:57.660+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.18.ddb7251d-3373-444c-8ef9-9dae6e0ca5ee.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/18
[2024-05-20T00:09:57.665+0000] {spark_submit.py:571} INFO - 24/05/20 00:09:57 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:09:57.666+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:09:57.666+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:09:57.666+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:09:57.667+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:09:56.199Z",
[2024-05-20T00:09:57.667+0000] {spark_submit.py:571} INFO - "batchId" : 18,
[2024-05-20T00:09:57.667+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:09:57.667+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 83.33333333333333,
[2024-05-20T00:09:57.667+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.6839945280437757,
[2024-05-20T00:09:57.667+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:09:57.668+0000] {spark_submit.py:571} INFO - "addBatch" : 1212,
[2024-05-20T00:09:57.668+0000] {spark_submit.py:571} INFO - "commitOffsets" : 106,
[2024-05-20T00:09:57.668+0000] {spark_submit.py:571} INFO - "getBatch" : 2,
[2024-05-20T00:09:57.668+0000] {spark_submit.py:571} INFO - "latestOffset" : 1,
[2024-05-20T00:09:57.668+0000] {spark_submit.py:571} INFO - "queryPlanning" : 48,
[2024-05-20T00:09:57.668+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1462,
[2024-05-20T00:09:57.669+0000] {spark_submit.py:571} INFO - "walCommit" : 76
[2024-05-20T00:09:57.669+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:09:57.669+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:09:57.669+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:09:57.669+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:09:57.670+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:09:57.670+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:09:57.670+0000] {spark_submit.py:571} INFO - "0" : 41
[2024-05-20T00:09:57.670+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:09:57.670+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:09:57.670+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:09:57.670+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:09:57.670+0000] {spark_submit.py:571} INFO - "0" : 42
[2024-05-20T00:09:57.671+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:09:57.671+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:09:57.671+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:09:57.671+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:09:57.671+0000] {spark_submit.py:571} INFO - "0" : 42
[2024-05-20T00:09:57.671+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:09:57.671+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:09:57.671+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:09:57.671+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 83.33333333333333,
[2024-05-20T00:09:57.672+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.6839945280437757,
[2024-05-20T00:09:57.672+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:09:57.672+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:09:57.672+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:09:57.672+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:09:57.672+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:09:57.672+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:09:57.672+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:09:57.672+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:09:57.673+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:09:57.673+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:09:57.673+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:10:07.685+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:10:17.694+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:10:22.743+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/19 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.19.dc5fed15-066d-47f3-920c-573d3d3d13a1.tmp
[2024-05-20T00:10:22.768+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.19.dc5fed15-066d-47f3-920c-573d3d3d13a1.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/19
[2024-05-20T00:10:22.769+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO MicroBatchExecution: Committed offsets for batch 19. Metadata OffsetSeqMetadata(0,1716163822699,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:10:22.860+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:10:22.864+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:10:22.879+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:10:22.880+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:10:22.924+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:10:22.968+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:10:22.969+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO DAGScheduler: Got job 19 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:10:22.970+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO DAGScheduler: Final stage: ResultStage 19 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:10:22.970+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:10:22.970+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:10:22.970+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO DAGScheduler: Submitting ResultStage 19 (PythonRDD[199] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:10:22.973+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 69.8 KiB, free 434.2 MiB)
[2024-05-20T00:10:22.980+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.2 MiB)
[2024-05-20T00:10:22.981+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:10:22.981+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:10:22.982+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (PythonRDD[199] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:10:22.983+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
[2024-05-20T00:10:22.985+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:22 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:10:23.066+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:23 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:10:23.812+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:23 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 821 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:10:23.820+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:23 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool
[2024-05-20T00:10:23.820+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:23 INFO DAGScheduler: ResultStage 19 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.843 s
[2024-05-20T00:10:23.821+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:23 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:10:23.822+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
[2024-05-20T00:10:23.823+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:23 INFO DAGScheduler: Job 19 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.849038 s
[2024-05-20T00:10:23.884+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/19 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.19.46c8831a-2d49-438f-bb61-338256e76991.tmp
[2024-05-20T00:10:23.925+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.19.46c8831a-2d49-438f-bb61-338256e76991.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/19
[2024-05-20T00:10:23.946+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:23 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:10:23.947+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:10:23.948+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:10:23.948+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:10:23.949+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:10:22.694Z",
[2024-05-20T00:10:23.949+0000] {spark_submit.py:571} INFO - "batchId" : 19,
[2024-05-20T00:10:23.949+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:10:23.950+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:10:23.950+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.8116883116883117,
[2024-05-20T00:10:23.950+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:10:23.950+0000] {spark_submit.py:571} INFO - "addBatch" : 961,
[2024-05-20T00:10:23.950+0000] {spark_submit.py:571} INFO - "commitOffsets" : 94,
[2024-05-20T00:10:23.951+0000] {spark_submit.py:571} INFO - "getBatch" : 0,
[2024-05-20T00:10:23.951+0000] {spark_submit.py:571} INFO - "latestOffset" : 5,
[2024-05-20T00:10:23.951+0000] {spark_submit.py:571} INFO - "queryPlanning" : 96,
[2024-05-20T00:10:23.951+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1232,
[2024-05-20T00:10:23.951+0000] {spark_submit.py:571} INFO - "walCommit" : 71
[2024-05-20T00:10:23.951+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:10:23.952+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:10:23.952+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:10:23.952+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:10:23.952+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:10:23.952+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:10:23.952+0000] {spark_submit.py:571} INFO - "0" : 42
[2024-05-20T00:10:23.952+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:10:23.953+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:10:23.953+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:10:23.953+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:10:23.953+0000] {spark_submit.py:571} INFO - "0" : 43
[2024-05-20T00:10:23.953+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:10:23.953+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:10:23.954+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:10:23.954+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:10:23.954+0000] {spark_submit.py:571} INFO - "0" : 43
[2024-05-20T00:10:23.954+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:10:23.954+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:10:23.954+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:10:23.954+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:10:23.955+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.8116883116883117,
[2024-05-20T00:10:23.955+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:10:23.955+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:10:23.955+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:10:23.955+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:10:23.955+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:10:23.955+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:10:23.956+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:10:23.956+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:10:23.956+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:10:23.956+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:10:23.956+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:10:33.968+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:10:34.943+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:34 INFO BlockManagerInfo: Removed broadcast_19_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:10:34.953+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:34 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:10:34.960+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:34 INFO BlockManagerInfo: Removed broadcast_18_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:10:34.962+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:34 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:10:43.982+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:10:53.988+0000] {spark_submit.py:571} INFO - 24/05/20 00:10:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:11:03.819+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/20 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.20.6c7b5b64-e185-43e3-adbc-29f747f1a969.tmp
[2024-05-20T00:11:03.866+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/.20.6c7b5b64-e185-43e3-adbc-29f747f1a969.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/offsets/20
[2024-05-20T00:11:03.867+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:03 INFO MicroBatchExecution: Committed offsets for batch 20. Metadata OffsetSeqMetadata(0,1716163863762,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2024-05-20T00:11:03.991+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:03 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:11:03.997+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:03 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:11:04.040+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:11:04.041+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2024-05-20T00:11:04.085+0000] {spark_submit.py:571} INFO - INFO:py4j.clientserver:Received command c on object id p0
[2024-05-20T00:11:04.156+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO SparkContext: Starting job: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2024-05-20T00:11:04.160+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO DAGScheduler: Got job 20 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2024-05-20T00:11:04.161+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO DAGScheduler: Final stage: ResultStage 20 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2024-05-20T00:11:04.161+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO DAGScheduler: Parents of final stage: List()
[2024-05-20T00:11:04.162+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO DAGScheduler: Missing parents: List()
[2024-05-20T00:11:04.162+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO DAGScheduler: Submitting ResultStage 20 (PythonRDD[209] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2024-05-20T00:11:04.167+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 69.8 KiB, free 434.3 MiB)
[2024-05-20T00:11:04.191+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 434.3 MiB)
[2024-05-20T00:11:04.193+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on eddd84e36bad:43929 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:11:04.193+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1585
[2024-05-20T00:11:04.197+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (PythonRDD[209] at call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2024-05-20T00:11:04.197+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
[2024-05-20T00:11:04.202+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (192.168.96.6, executor 0, partition 0, PROCESS_LOCAL, 14270 bytes)
[2024-05-20T00:11:04.289+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:04 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 192.168.96.6:44029 (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:11:05.116+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:05 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 913 ms on 192.168.96.6 (executor 0) (1/1)
[2024-05-20T00:11:05.125+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:05 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2024-05-20T00:11:05.126+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:05 INFO DAGScheduler: ResultStage 20 (call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.956 s
[2024-05-20T00:11:05.128+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:05 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-05-20T00:11:05.130+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
[2024-05-20T00:11:05.130+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:05 INFO DAGScheduler: Job 20 finished: call at /home/***/.local/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.969008 s
[2024-05-20T00:11:05.196+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/20 using temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.20.0f53a70c-a536-40c6-adb2-0a2cf274e13d.tmp
[2024-05-20T00:11:05.251+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/.20.0f53a70c-a536-40c6-adb2-0a2cf274e13d.tmp to file:/tmp/temporary-40af458f-482f-48ad-a7d8-84e60ceb79ba/commits/20
[2024-05-20T00:11:05.265+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:05 INFO MicroBatchExecution: Streaming query made progress: {
[2024-05-20T00:11:05.266+0000] {spark_submit.py:571} INFO - "id" : "483fceee-2997-4112-9685-5530c8c769e0",
[2024-05-20T00:11:05.267+0000] {spark_submit.py:571} INFO - "runId" : "f4941a1d-2d71-4d43-9364-aeb0c5b4b17e",
[2024-05-20T00:11:05.267+0000] {spark_submit.py:571} INFO - "name" : null,
[2024-05-20T00:11:05.268+0000] {spark_submit.py:571} INFO - "timestamp" : "2024-05-20T00:11:03.760Z",
[2024-05-20T00:11:05.268+0000] {spark_submit.py:571} INFO - "batchId" : 20,
[2024-05-20T00:11:05.269+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:11:05.269+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:11:05.269+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.6702412868632708,
[2024-05-20T00:11:05.270+0000] {spark_submit.py:571} INFO - "durationMs" : {
[2024-05-20T00:11:05.270+0000] {spark_submit.py:571} INFO - "addBatch" : 1133,
[2024-05-20T00:11:05.270+0000] {spark_submit.py:571} INFO - "commitOffsets" : 103,
[2024-05-20T00:11:05.271+0000] {spark_submit.py:571} INFO - "getBatch" : 0,
[2024-05-20T00:11:05.271+0000] {spark_submit.py:571} INFO - "latestOffset" : 2,
[2024-05-20T00:11:05.272+0000] {spark_submit.py:571} INFO - "queryPlanning" : 124,
[2024-05-20T00:11:05.272+0000] {spark_submit.py:571} INFO - "triggerExecution" : 1492,
[2024-05-20T00:11:05.272+0000] {spark_submit.py:571} INFO - "walCommit" : 107
[2024-05-20T00:11:05.273+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:11:05.274+0000] {spark_submit.py:571} INFO - "stateOperators" : [ ],
[2024-05-20T00:11:05.274+0000] {spark_submit.py:571} INFO - "sources" : [ {
[2024-05-20T00:11:05.277+0000] {spark_submit.py:571} INFO - "description" : "KafkaV2[Subscribe[redfin_properties]]",
[2024-05-20T00:11:05.278+0000] {spark_submit.py:571} INFO - "startOffset" : {
[2024-05-20T00:11:05.278+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:11:05.281+0000] {spark_submit.py:571} INFO - "0" : 43
[2024-05-20T00:11:05.281+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:11:05.282+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:11:05.282+0000] {spark_submit.py:571} INFO - "endOffset" : {
[2024-05-20T00:11:05.283+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:11:05.283+0000] {spark_submit.py:571} INFO - "0" : 44
[2024-05-20T00:11:05.283+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:11:05.283+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:11:05.283+0000] {spark_submit.py:571} INFO - "latestOffset" : {
[2024-05-20T00:11:05.283+0000] {spark_submit.py:571} INFO - "redfin_properties" : {
[2024-05-20T00:11:05.284+0000] {spark_submit.py:571} INFO - "0" : 44
[2024-05-20T00:11:05.284+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:11:05.284+0000] {spark_submit.py:571} INFO - },
[2024-05-20T00:11:05.284+0000] {spark_submit.py:571} INFO - "numInputRows" : 1,
[2024-05-20T00:11:05.284+0000] {spark_submit.py:571} INFO - "inputRowsPerSecond" : 76.92307692307692,
[2024-05-20T00:11:05.284+0000] {spark_submit.py:571} INFO - "processedRowsPerSecond" : 0.6702412868632708,
[2024-05-20T00:11:05.284+0000] {spark_submit.py:571} INFO - "metrics" : {
[2024-05-20T00:11:05.285+0000] {spark_submit.py:571} INFO - "avgOffsetsBehindLatest" : "0.0",
[2024-05-20T00:11:05.285+0000] {spark_submit.py:571} INFO - "maxOffsetsBehindLatest" : "0",
[2024-05-20T00:11:05.285+0000] {spark_submit.py:571} INFO - "minOffsetsBehindLatest" : "0"
[2024-05-20T00:11:05.285+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:11:05.285+0000] {spark_submit.py:571} INFO - } ],
[2024-05-20T00:11:05.285+0000] {spark_submit.py:571} INFO - "sink" : {
[2024-05-20T00:11:05.285+0000] {spark_submit.py:571} INFO - "description" : "ForeachBatchSink",
[2024-05-20T00:11:05.285+0000] {spark_submit.py:571} INFO - "numOutputRows" : -1
[2024-05-20T00:11:05.285+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:11:05.286+0000] {spark_submit.py:571} INFO - }
[2024-05-20T00:11:15.261+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:11:17.458+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:17 INFO BlockManagerInfo: Removed broadcast_20_piece0 on eddd84e36bad:43929 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:11:17.468+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:17 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 192.168.96.6:44029 in memory (size: 25.5 KiB, free: 434.4 MiB)
[2024-05-20T00:11:25.269+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:11:35.269+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:11:45.281+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:11:55.289+0000] {spark_submit.py:571} INFO - 24/05/20 00:11:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:12:05.301+0000] {spark_submit.py:571} INFO - 24/05/20 00:12:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:12:15.304+0000] {spark_submit.py:571} INFO - 24/05/20 00:12:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:12:25.312+0000] {spark_submit.py:571} INFO - 24/05/20 00:12:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:12:35.313+0000] {spark_submit.py:571} INFO - 24/05/20 00:12:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:12:45.311+0000] {spark_submit.py:571} INFO - 24/05/20 00:12:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:12:55.327+0000] {spark_submit.py:571} INFO - 24/05/20 00:12:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:13:05.336+0000] {spark_submit.py:571} INFO - 24/05/20 00:13:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:13:15.343+0000] {spark_submit.py:571} INFO - 24/05/20 00:13:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:13:25.348+0000] {spark_submit.py:571} INFO - 24/05/20 00:13:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:13:35.357+0000] {spark_submit.py:571} INFO - 24/05/20 00:13:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:13:45.365+0000] {spark_submit.py:571} INFO - 24/05/20 00:13:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:13:55.371+0000] {spark_submit.py:571} INFO - 24/05/20 00:13:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:14:05.375+0000] {spark_submit.py:571} INFO - 24/05/20 00:14:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:14:15.385+0000] {spark_submit.py:571} INFO - 24/05/20 00:14:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:14:25.393+0000] {spark_submit.py:571} INFO - 24/05/20 00:14:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:14:35.407+0000] {spark_submit.py:571} INFO - 24/05/20 00:14:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:14:45.429+0000] {spark_submit.py:571} INFO - 24/05/20 00:14:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:14:55.488+0000] {spark_submit.py:571} INFO - 24/05/20 00:14:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:15:05.450+0000] {spark_submit.py:571} INFO - 24/05/20 00:15:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:15:15.458+0000] {spark_submit.py:571} INFO - 24/05/20 00:15:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:15:25.472+0000] {spark_submit.py:571} INFO - 24/05/20 00:15:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:15:35.483+0000] {spark_submit.py:571} INFO - 24/05/20 00:15:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:15:45.493+0000] {spark_submit.py:571} INFO - 24/05/20 00:15:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:15:55.504+0000] {spark_submit.py:571} INFO - 24/05/20 00:15:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:16:05.523+0000] {spark_submit.py:571} INFO - 24/05/20 00:16:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:16:15.543+0000] {spark_submit.py:571} INFO - 24/05/20 00:16:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:16:25.553+0000] {spark_submit.py:571} INFO - 24/05/20 00:16:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:16:35.566+0000] {spark_submit.py:571} INFO - 24/05/20 00:16:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:16:45.576+0000] {spark_submit.py:571} INFO - 24/05/20 00:16:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:16:55.589+0000] {spark_submit.py:571} INFO - 24/05/20 00:16:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:17:05.594+0000] {spark_submit.py:571} INFO - 24/05/20 00:17:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:17:15.605+0000] {spark_submit.py:571} INFO - 24/05/20 00:17:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:17:25.610+0000] {spark_submit.py:571} INFO - 24/05/20 00:17:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:17:35.615+0000] {spark_submit.py:571} INFO - 24/05/20 00:17:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:17:45.620+0000] {spark_submit.py:571} INFO - 24/05/20 00:17:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:17:55.628+0000] {spark_submit.py:571} INFO - 24/05/20 00:17:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:18:05.636+0000] {spark_submit.py:571} INFO - 24/05/20 00:18:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:18:15.636+0000] {spark_submit.py:571} INFO - 24/05/20 00:18:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:18:25.639+0000] {spark_submit.py:571} INFO - 24/05/20 00:18:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:18:35.638+0000] {spark_submit.py:571} INFO - 24/05/20 00:18:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:18:45.654+0000] {spark_submit.py:571} INFO - 24/05/20 00:18:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:18:55.658+0000] {spark_submit.py:571} INFO - 24/05/20 00:18:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:19:05.671+0000] {spark_submit.py:571} INFO - 24/05/20 00:19:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:19:15.667+0000] {spark_submit.py:571} INFO - 24/05/20 00:19:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:19:25.697+0000] {spark_submit.py:571} INFO - 24/05/20 00:19:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:19:35.714+0000] {spark_submit.py:571} INFO - 24/05/20 00:19:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:19:45.713+0000] {spark_submit.py:571} INFO - 24/05/20 00:19:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:19:55.732+0000] {spark_submit.py:571} INFO - 24/05/20 00:19:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:20:05.725+0000] {spark_submit.py:571} INFO - 24/05/20 00:20:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:20:15.757+0000] {spark_submit.py:571} INFO - 24/05/20 00:20:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:20:25.740+0000] {spark_submit.py:571} INFO - 24/05/20 00:20:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:20:35.747+0000] {spark_submit.py:571} INFO - 24/05/20 00:20:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:20:45.748+0000] {spark_submit.py:571} INFO - 24/05/20 00:20:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:20:55.826+0000] {spark_submit.py:571} INFO - 24/05/20 00:20:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:21:05.768+0000] {spark_submit.py:571} INFO - 24/05/20 00:21:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:21:15.796+0000] {spark_submit.py:571} INFO - 24/05/20 00:21:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:21:25.826+0000] {spark_submit.py:571} INFO - 24/05/20 00:21:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:21:35.818+0000] {spark_submit.py:571} INFO - 24/05/20 00:21:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:21:45.818+0000] {spark_submit.py:571} INFO - 24/05/20 00:21:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:21:55.819+0000] {spark_submit.py:571} INFO - 24/05/20 00:21:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:22:05.824+0000] {spark_submit.py:571} INFO - 24/05/20 00:22:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:22:15.825+0000] {spark_submit.py:571} INFO - 24/05/20 00:22:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:22:25.828+0000] {spark_submit.py:571} INFO - 24/05/20 00:22:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:22:35.839+0000] {spark_submit.py:571} INFO - 24/05/20 00:22:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:22:45.838+0000] {spark_submit.py:571} INFO - 24/05/20 00:22:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:22:55.856+0000] {spark_submit.py:571} INFO - 24/05/20 00:22:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:23:05.848+0000] {spark_submit.py:571} INFO - 24/05/20 00:23:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:23:15.865+0000] {spark_submit.py:571} INFO - 24/05/20 00:23:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:23:25.861+0000] {spark_submit.py:571} INFO - 24/05/20 00:23:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:23:35.865+0000] {spark_submit.py:571} INFO - 24/05/20 00:23:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:23:45.881+0000] {spark_submit.py:571} INFO - 24/05/20 00:23:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:23:55.908+0000] {spark_submit.py:571} INFO - 24/05/20 00:23:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:24:05.904+0000] {spark_submit.py:571} INFO - 24/05/20 00:24:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:24:15.919+0000] {spark_submit.py:571} INFO - 24/05/20 00:24:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:24:25.919+0000] {spark_submit.py:571} INFO - 24/05/20 00:24:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:24:35.932+0000] {spark_submit.py:571} INFO - 24/05/20 00:24:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:24:45.943+0000] {spark_submit.py:571} INFO - 24/05/20 00:24:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:24:55.951+0000] {spark_submit.py:571} INFO - 24/05/20 00:24:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:25:05.952+0000] {spark_submit.py:571} INFO - 24/05/20 00:25:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:25:15.985+0000] {spark_submit.py:571} INFO - 24/05/20 00:25:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:25:25.969+0000] {spark_submit.py:571} INFO - 24/05/20 00:25:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:25:35.980+0000] {spark_submit.py:571} INFO - 24/05/20 00:25:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:25:45.981+0000] {spark_submit.py:571} INFO - 24/05/20 00:25:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:25:55.992+0000] {spark_submit.py:571} INFO - 24/05/20 00:25:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:26:06.001+0000] {spark_submit.py:571} INFO - 24/05/20 00:26:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:26:16.012+0000] {spark_submit.py:571} INFO - 24/05/20 00:26:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:26:26.008+0000] {spark_submit.py:571} INFO - 24/05/20 00:26:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:26:36.022+0000] {spark_submit.py:571} INFO - 24/05/20 00:26:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:26:46.020+0000] {spark_submit.py:571} INFO - 24/05/20 00:26:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:26:56.046+0000] {spark_submit.py:571} INFO - 24/05/20 00:26:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:27:06.056+0000] {spark_submit.py:571} INFO - 24/05/20 00:27:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:27:16.063+0000] {spark_submit.py:571} INFO - 24/05/20 00:27:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:27:26.074+0000] {spark_submit.py:571} INFO - 24/05/20 00:27:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:27:36.072+0000] {spark_submit.py:571} INFO - 24/05/20 00:27:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:27:46.085+0000] {spark_submit.py:571} INFO - 24/05/20 00:27:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:27:56.089+0000] {spark_submit.py:571} INFO - 24/05/20 00:27:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:28:06.103+0000] {spark_submit.py:571} INFO - 24/05/20 00:28:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:28:16.114+0000] {spark_submit.py:571} INFO - 24/05/20 00:28:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:28:26.119+0000] {spark_submit.py:571} INFO - 24/05/20 00:28:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:28:36.132+0000] {spark_submit.py:571} INFO - 24/05/20 00:28:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:28:46.145+0000] {spark_submit.py:571} INFO - 24/05/20 00:28:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:28:56.151+0000] {spark_submit.py:571} INFO - 24/05/20 00:28:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:29:06.154+0000] {spark_submit.py:571} INFO - 24/05/20 00:29:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:29:16.168+0000] {spark_submit.py:571} INFO - 24/05/20 00:29:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:29:26.177+0000] {spark_submit.py:571} INFO - 24/05/20 00:29:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:29:36.194+0000] {spark_submit.py:571} INFO - 24/05/20 00:29:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:29:46.190+0000] {spark_submit.py:571} INFO - 24/05/20 00:29:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:29:56.187+0000] {spark_submit.py:571} INFO - 24/05/20 00:29:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:30:06.195+0000] {spark_submit.py:571} INFO - 24/05/20 00:30:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:30:16.202+0000] {spark_submit.py:571} INFO - 24/05/20 00:30:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:30:26.210+0000] {spark_submit.py:571} INFO - 24/05/20 00:30:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:30:36.229+0000] {spark_submit.py:571} INFO - 24/05/20 00:30:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:30:46.249+0000] {spark_submit.py:571} INFO - 24/05/20 00:30:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:30:56.258+0000] {spark_submit.py:571} INFO - 24/05/20 00:30:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:31:06.268+0000] {spark_submit.py:571} INFO - 24/05/20 00:31:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:31:16.283+0000] {spark_submit.py:571} INFO - 24/05/20 00:31:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:31:26.278+0000] {spark_submit.py:571} INFO - 24/05/20 00:31:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:31:36.294+0000] {spark_submit.py:571} INFO - 24/05/20 00:31:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:31:46.302+0000] {spark_submit.py:571} INFO - 24/05/20 00:31:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:31:56.339+0000] {spark_submit.py:571} INFO - 24/05/20 00:31:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:32:06.330+0000] {spark_submit.py:571} INFO - 24/05/20 00:32:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:32:16.334+0000] {spark_submit.py:571} INFO - 24/05/20 00:32:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:32:26.338+0000] {spark_submit.py:571} INFO - 24/05/20 00:32:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:32:36.339+0000] {spark_submit.py:571} INFO - 24/05/20 00:32:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:32:46.352+0000] {spark_submit.py:571} INFO - 24/05/20 00:32:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:32:56.364+0000] {spark_submit.py:571} INFO - 24/05/20 00:32:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:33:06.368+0000] {spark_submit.py:571} INFO - 24/05/20 00:33:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:33:16.370+0000] {spark_submit.py:571} INFO - 24/05/20 00:33:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:33:26.372+0000] {spark_submit.py:571} INFO - 24/05/20 00:33:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:33:36.381+0000] {spark_submit.py:571} INFO - 24/05/20 00:33:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:33:46.388+0000] {spark_submit.py:571} INFO - 24/05/20 00:33:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:33:56.395+0000] {spark_submit.py:571} INFO - 24/05/20 00:33:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:34:06.396+0000] {spark_submit.py:571} INFO - 24/05/20 00:34:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:34:16.407+0000] {spark_submit.py:571} INFO - 24/05/20 00:34:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:34:26.412+0000] {spark_submit.py:571} INFO - 24/05/20 00:34:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:34:36.416+0000] {spark_submit.py:571} INFO - 24/05/20 00:34:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:34:46.426+0000] {spark_submit.py:571} INFO - 24/05/20 00:34:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:34:56.479+0000] {spark_submit.py:571} INFO - 24/05/20 00:34:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:35:06.440+0000] {spark_submit.py:571} INFO - 24/05/20 00:35:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:35:16.440+0000] {spark_submit.py:571} INFO - 24/05/20 00:35:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:35:26.446+0000] {spark_submit.py:571} INFO - 24/05/20 00:35:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:35:36.453+0000] {spark_submit.py:571} INFO - 24/05/20 00:35:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:35:46.464+0000] {spark_submit.py:571} INFO - 24/05/20 00:35:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:35:56.475+0000] {spark_submit.py:571} INFO - 24/05/20 00:35:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:36:06.478+0000] {spark_submit.py:571} INFO - 24/05/20 00:36:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:36:16.483+0000] {spark_submit.py:571} INFO - 24/05/20 00:36:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:36:26.494+0000] {spark_submit.py:571} INFO - 24/05/20 00:36:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:36:36.501+0000] {spark_submit.py:571} INFO - 24/05/20 00:36:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:36:46.504+0000] {spark_submit.py:571} INFO - 24/05/20 00:36:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:36:56.558+0000] {spark_submit.py:571} INFO - 24/05/20 00:36:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:37:06.569+0000] {spark_submit.py:571} INFO - 24/05/20 00:37:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:37:16.577+0000] {spark_submit.py:571} INFO - 24/05/20 00:37:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:37:26.588+0000] {spark_submit.py:571} INFO - 24/05/20 00:37:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:37:36.602+0000] {spark_submit.py:571} INFO - 24/05/20 00:37:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:37:46.605+0000] {spark_submit.py:571} INFO - 24/05/20 00:37:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:37:56.616+0000] {spark_submit.py:571} INFO - 24/05/20 00:37:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:38:06.628+0000] {spark_submit.py:571} INFO - 24/05/20 00:38:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:38:16.632+0000] {spark_submit.py:571} INFO - 24/05/20 00:38:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:38:26.643+0000] {spark_submit.py:571} INFO - 24/05/20 00:38:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:38:36.651+0000] {spark_submit.py:571} INFO - 24/05/20 00:38:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:38:46.652+0000] {spark_submit.py:571} INFO - 24/05/20 00:38:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:38:56.658+0000] {spark_submit.py:571} INFO - 24/05/20 00:38:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:39:06.658+0000] {spark_submit.py:571} INFO - 24/05/20 00:39:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:39:16.661+0000] {spark_submit.py:571} INFO - 24/05/20 00:39:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:39:26.668+0000] {spark_submit.py:571} INFO - 24/05/20 00:39:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:39:36.669+0000] {spark_submit.py:571} INFO - 24/05/20 00:39:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:39:46.680+0000] {spark_submit.py:571} INFO - 24/05/20 00:39:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:39:56.692+0000] {spark_submit.py:571} INFO - 24/05/20 00:39:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:40:06.697+0000] {spark_submit.py:571} INFO - 24/05/20 00:40:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:40:16.701+0000] {spark_submit.py:571} INFO - 24/05/20 00:40:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:40:26.711+0000] {spark_submit.py:571} INFO - 24/05/20 00:40:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:40:36.715+0000] {spark_submit.py:571} INFO - 24/05/20 00:40:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:40:46.732+0000] {spark_submit.py:571} INFO - 24/05/20 00:40:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:40:56.753+0000] {spark_submit.py:571} INFO - 24/05/20 00:40:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:41:06.753+0000] {spark_submit.py:571} INFO - 24/05/20 00:41:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:41:16.763+0000] {spark_submit.py:571} INFO - 24/05/20 00:41:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:41:26.773+0000] {spark_submit.py:571} INFO - 24/05/20 00:41:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:41:36.773+0000] {spark_submit.py:571} INFO - 24/05/20 00:41:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:41:46.776+0000] {spark_submit.py:571} INFO - 24/05/20 00:41:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:41:56.800+0000] {spark_submit.py:571} INFO - 24/05/20 00:41:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:42:06.785+0000] {spark_submit.py:571} INFO - 24/05/20 00:42:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:42:16.803+0000] {spark_submit.py:571} INFO - 24/05/20 00:42:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:42:26.797+0000] {spark_submit.py:571} INFO - 24/05/20 00:42:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:42:36.801+0000] {spark_submit.py:571} INFO - 24/05/20 00:42:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:42:46.805+0000] {spark_submit.py:571} INFO - 24/05/20 00:42:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:42:56.821+0000] {spark_submit.py:571} INFO - 24/05/20 00:42:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:43:06.827+0000] {spark_submit.py:571} INFO - 24/05/20 00:43:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:43:16.831+0000] {spark_submit.py:571} INFO - 24/05/20 00:43:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:43:26.842+0000] {spark_submit.py:571} INFO - 24/05/20 00:43:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:43:36.852+0000] {spark_submit.py:571} INFO - 24/05/20 00:43:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:43:46.862+0000] {spark_submit.py:571} INFO - 24/05/20 00:43:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:43:56.873+0000] {spark_submit.py:571} INFO - 24/05/20 00:43:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:44:06.896+0000] {spark_submit.py:571} INFO - 24/05/20 00:44:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:44:16.891+0000] {spark_submit.py:571} INFO - 24/05/20 00:44:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:44:26.902+0000] {spark_submit.py:571} INFO - 24/05/20 00:44:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:44:36.903+0000] {spark_submit.py:571} INFO - 24/05/20 00:44:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:44:46.916+0000] {spark_submit.py:571} INFO - 24/05/20 00:44:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:44:56.921+0000] {spark_submit.py:571} INFO - 24/05/20 00:44:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:45:06.921+0000] {spark_submit.py:571} INFO - 24/05/20 00:45:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:45:16.923+0000] {spark_submit.py:571} INFO - 24/05/20 00:45:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:45:26.931+0000] {spark_submit.py:571} INFO - 24/05/20 00:45:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:45:36.955+0000] {spark_submit.py:571} INFO - 24/05/20 00:45:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:45:46.941+0000] {spark_submit.py:571} INFO - 24/05/20 00:45:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:45:56.954+0000] {spark_submit.py:571} INFO - 24/05/20 00:45:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:46:06.965+0000] {spark_submit.py:571} INFO - 24/05/20 00:46:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:46:16.989+0000] {spark_submit.py:571} INFO - 24/05/20 00:46:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:46:26.997+0000] {spark_submit.py:571} INFO - 24/05/20 00:46:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:46:37.006+0000] {spark_submit.py:571} INFO - 24/05/20 00:46:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:46:47.018+0000] {spark_submit.py:571} INFO - 24/05/20 00:46:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:46:57.039+0000] {spark_submit.py:571} INFO - 24/05/20 00:46:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:47:07.025+0000] {spark_submit.py:571} INFO - 24/05/20 00:47:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:47:17.033+0000] {spark_submit.py:571} INFO - 24/05/20 00:47:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:47:27.032+0000] {spark_submit.py:571} INFO - 24/05/20 00:47:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:47:37.040+0000] {spark_submit.py:571} INFO - 24/05/20 00:47:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:47:47.050+0000] {spark_submit.py:571} INFO - 24/05/20 00:47:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:47:57.059+0000] {spark_submit.py:571} INFO - 24/05/20 00:47:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:48:07.062+0000] {spark_submit.py:571} INFO - 24/05/20 00:48:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:48:17.084+0000] {spark_submit.py:571} INFO - 24/05/20 00:48:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:48:27.076+0000] {spark_submit.py:571} INFO - 24/05/20 00:48:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:48:37.086+0000] {spark_submit.py:571} INFO - 24/05/20 00:48:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:48:47.097+0000] {spark_submit.py:571} INFO - 24/05/20 00:48:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:48:57.100+0000] {spark_submit.py:571} INFO - 24/05/20 00:48:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:49:07.111+0000] {spark_submit.py:571} INFO - 24/05/20 00:49:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:49:17.133+0000] {spark_submit.py:571} INFO - 24/05/20 00:49:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:49:27.181+0000] {spark_submit.py:571} INFO - 24/05/20 00:49:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:49:37.166+0000] {spark_submit.py:571} INFO - 24/05/20 00:49:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:49:47.154+0000] {spark_submit.py:571} INFO - 24/05/20 00:49:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:49:57.174+0000] {spark_submit.py:571} INFO - 24/05/20 00:49:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:50:07.170+0000] {spark_submit.py:571} INFO - 24/05/20 00:50:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:50:17.178+0000] {spark_submit.py:571} INFO - 24/05/20 00:50:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:50:27.237+0000] {spark_submit.py:571} INFO - 24/05/20 00:50:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:50:37.200+0000] {spark_submit.py:571} INFO - 24/05/20 00:50:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:50:47.216+0000] {spark_submit.py:571} INFO - 24/05/20 00:50:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:50:57.210+0000] {spark_submit.py:571} INFO - 24/05/20 00:50:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:51:07.216+0000] {spark_submit.py:571} INFO - 24/05/20 00:51:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:51:17.219+0000] {spark_submit.py:571} INFO - 24/05/20 00:51:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:51:27.225+0000] {spark_submit.py:571} INFO - 24/05/20 00:51:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:51:37.233+0000] {spark_submit.py:571} INFO - 24/05/20 00:51:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:51:47.236+0000] {spark_submit.py:571} INFO - 24/05/20 00:51:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:51:57.236+0000] {spark_submit.py:571} INFO - 24/05/20 00:51:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:52:07.237+0000] {spark_submit.py:571} INFO - 24/05/20 00:52:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:52:17.236+0000] {spark_submit.py:571} INFO - 24/05/20 00:52:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:52:27.263+0000] {spark_submit.py:571} INFO - 24/05/20 00:52:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:52:37.256+0000] {spark_submit.py:571} INFO - 24/05/20 00:52:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:52:47.264+0000] {spark_submit.py:571} INFO - 24/05/20 00:52:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:52:57.273+0000] {spark_submit.py:571} INFO - 24/05/20 00:52:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:53:07.273+0000] {spark_submit.py:571} INFO - 24/05/20 00:53:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:53:17.279+0000] {spark_submit.py:571} INFO - 24/05/20 00:53:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:53:27.287+0000] {spark_submit.py:571} INFO - 24/05/20 00:53:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:53:37.294+0000] {spark_submit.py:571} INFO - 24/05/20 00:53:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:53:47.300+0000] {spark_submit.py:571} INFO - 24/05/20 00:53:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:53:57.318+0000] {spark_submit.py:571} INFO - 24/05/20 00:53:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:54:07.323+0000] {spark_submit.py:571} INFO - 24/05/20 00:54:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:54:17.326+0000] {spark_submit.py:571} INFO - 24/05/20 00:54:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:54:27.339+0000] {spark_submit.py:571} INFO - 24/05/20 00:54:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:54:37.349+0000] {spark_submit.py:571} INFO - 24/05/20 00:54:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:54:47.407+0000] {spark_submit.py:571} INFO - 24/05/20 00:54:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:54:57.407+0000] {spark_submit.py:571} INFO - 24/05/20 00:54:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:55:07.558+0000] {spark_submit.py:571} INFO - 24/05/20 00:55:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:55:17.537+0000] {spark_submit.py:571} INFO - 24/05/20 00:55:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:55:27.788+0000] {spark_submit.py:571} INFO - 24/05/20 00:55:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:55:37.808+0000] {spark_submit.py:571} INFO - 24/05/20 00:55:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:55:47.802+0000] {spark_submit.py:571} INFO - 24/05/20 00:55:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:55:57.812+0000] {spark_submit.py:571} INFO - 24/05/20 00:55:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:56:07.823+0000] {spark_submit.py:571} INFO - 24/05/20 00:56:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:56:17.835+0000] {spark_submit.py:571} INFO - 24/05/20 00:56:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:56:27.838+0000] {spark_submit.py:571} INFO - 24/05/20 00:56:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:56:37.863+0000] {spark_submit.py:571} INFO - 24/05/20 00:56:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:56:47.856+0000] {spark_submit.py:571} INFO - 24/05/20 00:56:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:56:57.868+0000] {spark_submit.py:571} INFO - 24/05/20 00:56:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:57:07.868+0000] {spark_submit.py:571} INFO - 24/05/20 00:57:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:57:17.869+0000] {spark_submit.py:571} INFO - 24/05/20 00:57:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:57:27.879+0000] {spark_submit.py:571} INFO - 24/05/20 00:57:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:57:37.904+0000] {spark_submit.py:571} INFO - 24/05/20 00:57:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:57:47.892+0000] {spark_submit.py:571} INFO - 24/05/20 00:57:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:57:57.899+0000] {spark_submit.py:571} INFO - 24/05/20 00:57:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:58:07.907+0000] {spark_submit.py:571} INFO - 24/05/20 00:58:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:58:18.245+0000] {spark_submit.py:571} INFO - 24/05/20 00:58:18 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:58:28.246+0000] {spark_submit.py:571} INFO - 24/05/20 00:58:28 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:58:38.250+0000] {spark_submit.py:571} INFO - 24/05/20 00:58:38 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:58:48.251+0000] {spark_submit.py:571} INFO - 24/05/20 00:58:48 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:58:58.267+0000] {spark_submit.py:571} INFO - 24/05/20 00:58:58 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:59:08.279+0000] {spark_submit.py:571} INFO - 24/05/20 00:59:08 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:59:18.269+0000] {spark_submit.py:571} INFO - 24/05/20 00:59:18 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:59:28.273+0000] {spark_submit.py:571} INFO - 24/05/20 00:59:28 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:59:38.284+0000] {spark_submit.py:571} INFO - 24/05/20 00:59:38 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:59:48.281+0000] {spark_submit.py:571} INFO - 24/05/20 00:59:48 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T00:59:58.281+0000] {spark_submit.py:571} INFO - 24/05/20 00:59:58 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:00:08.293+0000] {spark_submit.py:571} INFO - 24/05/20 01:00:08 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:00:18.324+0000] {spark_submit.py:571} INFO - 24/05/20 01:00:18 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:00:30.217+0000] {spark_submit.py:571} INFO - 24/05/20 01:00:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:00:40.225+0000] {spark_submit.py:571} INFO - 24/05/20 01:00:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:00:50.224+0000] {spark_submit.py:571} INFO - 24/05/20 01:00:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:01:00.232+0000] {spark_submit.py:571} INFO - 24/05/20 01:01:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:01:10.233+0000] {spark_submit.py:571} INFO - 24/05/20 01:01:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:01:20.269+0000] {spark_submit.py:571} INFO - 24/05/20 01:01:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:01:30.250+0000] {spark_submit.py:571} INFO - 24/05/20 01:01:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:01:40.257+0000] {spark_submit.py:571} INFO - 24/05/20 01:01:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:01:50.274+0000] {spark_submit.py:571} INFO - 24/05/20 01:01:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:02:00.267+0000] {spark_submit.py:571} INFO - 24/05/20 01:02:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:02:10.276+0000] {spark_submit.py:571} INFO - 24/05/20 01:02:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:02:20.289+0000] {spark_submit.py:571} INFO - 24/05/20 01:02:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:02:30.305+0000] {spark_submit.py:571} INFO - 24/05/20 01:02:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:02:40.304+0000] {spark_submit.py:571} INFO - 24/05/20 01:02:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:02:50.314+0000] {spark_submit.py:571} INFO - 24/05/20 01:02:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:03:00.318+0000] {spark_submit.py:571} INFO - 24/05/20 01:03:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:03:10.333+0000] {spark_submit.py:571} INFO - 24/05/20 01:03:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:03:20.343+0000] {spark_submit.py:571} INFO - 24/05/20 01:03:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:03:30.344+0000] {spark_submit.py:571} INFO - 24/05/20 01:03:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:03:40.344+0000] {spark_submit.py:571} INFO - 24/05/20 01:03:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:03:50.365+0000] {spark_submit.py:571} INFO - 24/05/20 01:03:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:04:00.354+0000] {spark_submit.py:571} INFO - 24/05/20 01:04:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:04:10.361+0000] {spark_submit.py:571} INFO - 24/05/20 01:04:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:04:20.370+0000] {spark_submit.py:571} INFO - 24/05/20 01:04:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:04:30.372+0000] {spark_submit.py:571} INFO - 24/05/20 01:04:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:04:40.384+0000] {spark_submit.py:571} INFO - 24/05/20 01:04:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:04:50.401+0000] {spark_submit.py:571} INFO - 24/05/20 01:04:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:05:00.402+0000] {spark_submit.py:571} INFO - 24/05/20 01:05:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:05:10.412+0000] {spark_submit.py:571} INFO - 24/05/20 01:05:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:05:20.414+0000] {spark_submit.py:571} INFO - 24/05/20 01:05:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:05:30.432+0000] {spark_submit.py:571} INFO - 24/05/20 01:05:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:05:40.426+0000] {spark_submit.py:571} INFO - 24/05/20 01:05:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:05:50.440+0000] {spark_submit.py:571} INFO - 24/05/20 01:05:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:06:00.442+0000] {spark_submit.py:571} INFO - 24/05/20 01:06:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:06:10.437+0000] {spark_submit.py:571} INFO - 24/05/20 01:06:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:06:20.456+0000] {spark_submit.py:571} INFO - 24/05/20 01:06:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:06:30.465+0000] {spark_submit.py:571} INFO - 24/05/20 01:06:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:06:40.481+0000] {spark_submit.py:571} INFO - 24/05/20 01:06:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:06:50.489+0000] {spark_submit.py:571} INFO - 24/05/20 01:06:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:07:00.506+0000] {spark_submit.py:571} INFO - 24/05/20 01:07:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:07:10.497+0000] {spark_submit.py:571} INFO - 24/05/20 01:07:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:07:20.500+0000] {spark_submit.py:571} INFO - 24/05/20 01:07:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:07:30.511+0000] {spark_submit.py:571} INFO - 24/05/20 01:07:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:07:40.514+0000] {spark_submit.py:571} INFO - 24/05/20 01:07:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:07:50.524+0000] {spark_submit.py:571} INFO - 24/05/20 01:07:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:08:00.528+0000] {spark_submit.py:571} INFO - 24/05/20 01:08:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:08:10.538+0000] {spark_submit.py:571} INFO - 24/05/20 01:08:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:08:20.543+0000] {spark_submit.py:571} INFO - 24/05/20 01:08:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:08:30.553+0000] {spark_submit.py:571} INFO - 24/05/20 01:08:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:08:40.563+0000] {spark_submit.py:571} INFO - 24/05/20 01:08:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:08:50.567+0000] {spark_submit.py:571} INFO - 24/05/20 01:08:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:09:00.573+0000] {spark_submit.py:571} INFO - 24/05/20 01:09:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:09:10.578+0000] {spark_submit.py:571} INFO - 24/05/20 01:09:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:09:20.576+0000] {spark_submit.py:571} INFO - 24/05/20 01:09:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:09:30.581+0000] {spark_submit.py:571} INFO - 24/05/20 01:09:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:09:40.580+0000] {spark_submit.py:571} INFO - 24/05/20 01:09:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:09:50.606+0000] {spark_submit.py:571} INFO - 24/05/20 01:09:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:10:00.611+0000] {spark_submit.py:571} INFO - 24/05/20 01:10:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:10:10.613+0000] {spark_submit.py:571} INFO - 24/05/20 01:10:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:10:20.652+0000] {spark_submit.py:571} INFO - 24/05/20 01:10:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:10:30.627+0000] {spark_submit.py:571} INFO - 24/05/20 01:10:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:10:40.638+0000] {spark_submit.py:571} INFO - 24/05/20 01:10:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:10:50.680+0000] {spark_submit.py:571} INFO - 24/05/20 01:10:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:11:00.687+0000] {spark_submit.py:571} INFO - 24/05/20 01:11:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:11:10.685+0000] {spark_submit.py:571} INFO - 24/05/20 01:11:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:11:20.696+0000] {spark_submit.py:571} INFO - 24/05/20 01:11:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:11:30.700+0000] {spark_submit.py:571} INFO - 24/05/20 01:11:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:11:40.707+0000] {spark_submit.py:571} INFO - 24/05/20 01:11:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:11:50.713+0000] {spark_submit.py:571} INFO - 24/05/20 01:11:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:12:00.714+0000] {spark_submit.py:571} INFO - 24/05/20 01:12:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:12:10.728+0000] {spark_submit.py:571} INFO - 24/05/20 01:12:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:12:20.740+0000] {spark_submit.py:571} INFO - 24/05/20 01:12:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:12:30.742+0000] {spark_submit.py:571} INFO - 24/05/20 01:12:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:12:40.779+0000] {spark_submit.py:571} INFO - 24/05/20 01:12:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:12:50.775+0000] {spark_submit.py:571} INFO - 24/05/20 01:12:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:13:00.777+0000] {spark_submit.py:571} INFO - 24/05/20 01:13:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:13:10.807+0000] {spark_submit.py:571} INFO - 24/05/20 01:13:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:13:20.798+0000] {spark_submit.py:571} INFO - 24/05/20 01:13:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:13:30.819+0000] {spark_submit.py:571} INFO - 24/05/20 01:13:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:13:40.812+0000] {spark_submit.py:571} INFO - 24/05/20 01:13:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:13:50.837+0000] {spark_submit.py:571} INFO - 24/05/20 01:13:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:14:00.841+0000] {spark_submit.py:571} INFO - 24/05/20 01:14:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:14:10.838+0000] {spark_submit.py:571} INFO - 24/05/20 01:14:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:14:20.857+0000] {spark_submit.py:571} INFO - 24/05/20 01:14:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:14:30.862+0000] {spark_submit.py:571} INFO - 24/05/20 01:14:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:14:40.870+0000] {spark_submit.py:571} INFO - 24/05/20 01:14:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:14:50.873+0000] {spark_submit.py:571} INFO - 24/05/20 01:14:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:15:00.877+0000] {spark_submit.py:571} INFO - 24/05/20 01:15:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:15:10.872+0000] {spark_submit.py:571} INFO - 24/05/20 01:15:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:15:20.886+0000] {spark_submit.py:571} INFO - 24/05/20 01:15:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:15:30.897+0000] {spark_submit.py:571} INFO - 24/05/20 01:15:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:15:40.900+0000] {spark_submit.py:571} INFO - 24/05/20 01:15:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:15:50.903+0000] {spark_submit.py:571} INFO - 24/05/20 01:15:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:16:00.903+0000] {spark_submit.py:571} INFO - 24/05/20 01:16:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:16:10.914+0000] {spark_submit.py:571} INFO - 24/05/20 01:16:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:16:20.905+0000] {spark_submit.py:571} INFO - 24/05/20 01:16:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:16:30.912+0000] {spark_submit.py:571} INFO - 24/05/20 01:16:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:16:40.920+0000] {spark_submit.py:571} INFO - 24/05/20 01:16:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:16:50.913+0000] {spark_submit.py:571} INFO - 24/05/20 01:16:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:17:00.921+0000] {spark_submit.py:571} INFO - 24/05/20 01:17:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:17:10.927+0000] {spark_submit.py:571} INFO - 24/05/20 01:17:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:17:20.939+0000] {spark_submit.py:571} INFO - 24/05/20 01:17:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:17:30.963+0000] {spark_submit.py:571} INFO - 24/05/20 01:17:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:17:40.961+0000] {spark_submit.py:571} INFO - 24/05/20 01:17:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:17:50.961+0000] {spark_submit.py:571} INFO - 24/05/20 01:17:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:18:00.975+0000] {spark_submit.py:571} INFO - 24/05/20 01:18:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:18:10.977+0000] {spark_submit.py:571} INFO - 24/05/20 01:18:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:18:20.990+0000] {spark_submit.py:571} INFO - 24/05/20 01:18:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:18:31.001+0000] {spark_submit.py:571} INFO - 24/05/20 01:18:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:18:41.008+0000] {spark_submit.py:571} INFO - 24/05/20 01:18:41 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:18:51.014+0000] {spark_submit.py:571} INFO - 24/05/20 01:18:51 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:19:01.020+0000] {spark_submit.py:571} INFO - 24/05/20 01:19:01 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:19:11.034+0000] {spark_submit.py:571} INFO - 24/05/20 01:19:11 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:19:21.038+0000] {spark_submit.py:571} INFO - 24/05/20 01:19:21 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:19:31.042+0000] {spark_submit.py:571} INFO - 24/05/20 01:19:31 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:19:41.050+0000] {spark_submit.py:571} INFO - 24/05/20 01:19:41 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:19:51.100+0000] {spark_submit.py:571} INFO - 24/05/20 01:19:51 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:20:01.068+0000] {spark_submit.py:571} INFO - 24/05/20 01:20:01 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:20:11.099+0000] {spark_submit.py:571} INFO - 24/05/20 01:20:11 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:20:21.071+0000] {spark_submit.py:571} INFO - 24/05/20 01:20:21 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:20:31.081+0000] {spark_submit.py:571} INFO - 24/05/20 01:20:31 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:20:41.093+0000] {spark_submit.py:571} INFO - 24/05/20 01:20:41 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:20:51.095+0000] {spark_submit.py:571} INFO - 24/05/20 01:20:51 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:21:01.097+0000] {spark_submit.py:571} INFO - 24/05/20 01:21:01 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:21:11.106+0000] {spark_submit.py:571} INFO - 24/05/20 01:21:11 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:21:21.118+0000] {spark_submit.py:571} INFO - 24/05/20 01:21:21 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:21:31.135+0000] {spark_submit.py:571} INFO - 24/05/20 01:21:31 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:21:41.146+0000] {spark_submit.py:571} INFO - 24/05/20 01:21:41 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:21:51.145+0000] {spark_submit.py:571} INFO - 24/05/20 01:21:51 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:22:01.155+0000] {spark_submit.py:571} INFO - 24/05/20 01:22:01 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:22:11.160+0000] {spark_submit.py:571} INFO - 24/05/20 01:22:11 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:22:21.167+0000] {spark_submit.py:571} INFO - 24/05/20 01:22:21 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:22:31.181+0000] {spark_submit.py:571} INFO - 24/05/20 01:22:31 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:22:41.191+0000] {spark_submit.py:571} INFO - 24/05/20 01:22:41 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:22:51.194+0000] {spark_submit.py:571} INFO - 24/05/20 01:22:51 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:23:01.221+0000] {spark_submit.py:571} INFO - 24/05/20 01:23:01 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:23:11.221+0000] {spark_submit.py:571} INFO - 24/05/20 01:23:11 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:23:21.217+0000] {spark_submit.py:571} INFO - 24/05/20 01:23:21 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:23:31.240+0000] {spark_submit.py:571} INFO - 24/05/20 01:23:31 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:23:41.232+0000] {spark_submit.py:571} INFO - 24/05/20 01:23:41 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:23:51.243+0000] {spark_submit.py:571} INFO - 24/05/20 01:23:51 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:24:01.245+0000] {spark_submit.py:571} INFO - 24/05/20 01:24:01 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:24:11.256+0000] {spark_submit.py:571} INFO - 24/05/20 01:24:11 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:24:21.270+0000] {spark_submit.py:571} INFO - 24/05/20 01:24:21 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:24:31.301+0000] {spark_submit.py:571} INFO - 24/05/20 01:24:31 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:24:41.281+0000] {spark_submit.py:571} INFO - 24/05/20 01:24:41 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:24:51.294+0000] {spark_submit.py:571} INFO - 24/05/20 01:24:51 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:25:01.302+0000] {spark_submit.py:571} INFO - 24/05/20 01:25:01 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:25:11.307+0000] {spark_submit.py:571} INFO - 24/05/20 01:25:11 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:25:21.314+0000] {spark_submit.py:571} INFO - 24/05/20 01:25:21 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:25:31.351+0000] {spark_submit.py:571} INFO - 24/05/20 01:25:31 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:25:41.335+0000] {spark_submit.py:571} INFO - 24/05/20 01:25:41 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:25:51.366+0000] {spark_submit.py:571} INFO - 24/05/20 01:25:51 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:26:01.342+0000] {spark_submit.py:571} INFO - 24/05/20 01:26:01 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:26:11.349+0000] {spark_submit.py:571} INFO - 24/05/20 01:26:11 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:26:21.353+0000] {spark_submit.py:571} INFO - 24/05/20 01:26:21 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:26:31.359+0000] {spark_submit.py:571} INFO - 24/05/20 01:26:31 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:26:41.372+0000] {spark_submit.py:571} INFO - 24/05/20 01:26:41 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:26:51.368+0000] {spark_submit.py:571} INFO - 24/05/20 01:26:51 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:27:01.373+0000] {spark_submit.py:571} INFO - 24/05/20 01:27:01 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:27:11.381+0000] {spark_submit.py:571} INFO - 24/05/20 01:27:11 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:27:21.381+0000] {spark_submit.py:571} INFO - 24/05/20 01:27:21 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:27:31.389+0000] {spark_submit.py:571} INFO - 24/05/20 01:27:31 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:27:41.397+0000] {spark_submit.py:571} INFO - 24/05/20 01:27:41 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:27:51.405+0000] {spark_submit.py:571} INFO - 24/05/20 01:27:51 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:28:01.435+0000] {spark_submit.py:571} INFO - 24/05/20 01:28:01 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:28:11.418+0000] {spark_submit.py:571} INFO - 24/05/20 01:28:11 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:28:21.431+0000] {spark_submit.py:571} INFO - 24/05/20 01:28:21 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:28:31.434+0000] {spark_submit.py:571} INFO - 24/05/20 01:28:31 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:28:41.441+0000] {spark_submit.py:571} INFO - 24/05/20 01:28:41 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:28:51.442+0000] {spark_submit.py:571} INFO - 24/05/20 01:28:51 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:29:01.453+0000] {spark_submit.py:571} INFO - 24/05/20 01:29:01 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:29:11.470+0000] {spark_submit.py:571} INFO - 24/05/20 01:29:11 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:29:21.467+0000] {spark_submit.py:571} INFO - 24/05/20 01:29:21 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:29:31.471+0000] {spark_submit.py:571} INFO - 24/05/20 01:29:31 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:29:41.482+0000] {spark_submit.py:571} INFO - 24/05/20 01:29:41 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:29:51.485+0000] {spark_submit.py:571} INFO - 24/05/20 01:29:51 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:30:01.487+0000] {spark_submit.py:571} INFO - 24/05/20 01:30:01 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:30:11.495+0000] {spark_submit.py:571} INFO - 24/05/20 01:30:11 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:30:22.563+0000] {spark_submit.py:571} INFO - 24/05/20 01:30:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:30:32.574+0000] {spark_submit.py:571} INFO - 24/05/20 01:30:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:30:42.577+0000] {spark_submit.py:571} INFO - 24/05/20 01:30:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:30:52.586+0000] {spark_submit.py:571} INFO - 24/05/20 01:30:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:31:02.600+0000] {spark_submit.py:571} INFO - 24/05/20 01:31:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:31:12.588+0000] {spark_submit.py:571} INFO - 24/05/20 01:31:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:31:22.583+0000] {spark_submit.py:571} INFO - 24/05/20 01:31:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:31:32.594+0000] {spark_submit.py:571} INFO - 24/05/20 01:31:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:31:42.599+0000] {spark_submit.py:571} INFO - 24/05/20 01:31:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:31:52.605+0000] {spark_submit.py:571} INFO - 24/05/20 01:31:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:32:02.612+0000] {spark_submit.py:571} INFO - 24/05/20 01:32:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:32:12.612+0000] {spark_submit.py:571} INFO - 24/05/20 01:32:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:32:22.628+0000] {spark_submit.py:571} INFO - 24/05/20 01:32:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:32:32.629+0000] {spark_submit.py:571} INFO - 24/05/20 01:32:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:32:42.633+0000] {spark_submit.py:571} INFO - 24/05/20 01:32:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:32:52.639+0000] {spark_submit.py:571} INFO - 24/05/20 01:32:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:33:02.657+0000] {spark_submit.py:571} INFO - 24/05/20 01:33:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:33:12.656+0000] {spark_submit.py:571} INFO - 24/05/20 01:33:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:33:22.667+0000] {spark_submit.py:571} INFO - 24/05/20 01:33:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:33:32.664+0000] {spark_submit.py:571} INFO - 24/05/20 01:33:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:33:42.668+0000] {spark_submit.py:571} INFO - 24/05/20 01:33:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:33:52.682+0000] {spark_submit.py:571} INFO - 24/05/20 01:33:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:34:02.690+0000] {spark_submit.py:571} INFO - 24/05/20 01:34:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:34:12.694+0000] {spark_submit.py:571} INFO - 24/05/20 01:34:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:34:22.697+0000] {spark_submit.py:571} INFO - 24/05/20 01:34:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:34:32.705+0000] {spark_submit.py:571} INFO - 24/05/20 01:34:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:34:42.710+0000] {spark_submit.py:571} INFO - 24/05/20 01:34:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:34:52.716+0000] {spark_submit.py:571} INFO - 24/05/20 01:34:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:35:02.726+0000] {spark_submit.py:571} INFO - 24/05/20 01:35:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:35:12.727+0000] {spark_submit.py:571} INFO - 24/05/20 01:35:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:35:22.736+0000] {spark_submit.py:571} INFO - 24/05/20 01:35:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:35:32.735+0000] {spark_submit.py:571} INFO - 24/05/20 01:35:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:35:42.748+0000] {spark_submit.py:571} INFO - 24/05/20 01:35:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:35:52.749+0000] {spark_submit.py:571} INFO - 24/05/20 01:35:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:36:02.744+0000] {spark_submit.py:571} INFO - 24/05/20 01:36:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:36:12.763+0000] {spark_submit.py:571} INFO - 24/05/20 01:36:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:36:22.768+0000] {spark_submit.py:571} INFO - 24/05/20 01:36:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:36:32.778+0000] {spark_submit.py:571} INFO - 24/05/20 01:36:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:36:42.787+0000] {spark_submit.py:571} INFO - 24/05/20 01:36:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:36:52.811+0000] {spark_submit.py:571} INFO - 24/05/20 01:36:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:37:02.821+0000] {spark_submit.py:571} INFO - 24/05/20 01:37:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:37:12.858+0000] {spark_submit.py:571} INFO - 24/05/20 01:37:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:37:22.833+0000] {spark_submit.py:571} INFO - 24/05/20 01:37:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:37:32.835+0000] {spark_submit.py:571} INFO - 24/05/20 01:37:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:37:42.844+0000] {spark_submit.py:571} INFO - 24/05/20 01:37:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:37:52.851+0000] {spark_submit.py:571} INFO - 24/05/20 01:37:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:38:02.864+0000] {spark_submit.py:571} INFO - 24/05/20 01:38:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:38:12.879+0000] {spark_submit.py:571} INFO - 24/05/20 01:38:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:38:22.882+0000] {spark_submit.py:571} INFO - 24/05/20 01:38:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:38:32.879+0000] {spark_submit.py:571} INFO - 24/05/20 01:38:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:38:42.888+0000] {spark_submit.py:571} INFO - 24/05/20 01:38:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:38:52.896+0000] {spark_submit.py:571} INFO - 24/05/20 01:38:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:39:02.925+0000] {spark_submit.py:571} INFO - 24/05/20 01:39:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:39:12.906+0000] {spark_submit.py:571} INFO - 24/05/20 01:39:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:39:22.915+0000] {spark_submit.py:571} INFO - 24/05/20 01:39:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:39:32.922+0000] {spark_submit.py:571} INFO - 24/05/20 01:39:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:39:42.923+0000] {spark_submit.py:571} INFO - 24/05/20 01:39:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:39:52.939+0000] {spark_submit.py:571} INFO - 24/05/20 01:39:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:40:02.945+0000] {spark_submit.py:571} INFO - 24/05/20 01:40:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:40:12.943+0000] {spark_submit.py:571} INFO - 24/05/20 01:40:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:40:22.947+0000] {spark_submit.py:571} INFO - 24/05/20 01:40:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:40:32.948+0000] {spark_submit.py:571} INFO - 24/05/20 01:40:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:40:42.986+0000] {spark_submit.py:571} INFO - 24/05/20 01:40:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:40:52.978+0000] {spark_submit.py:571} INFO - 24/05/20 01:40:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:41:02.998+0000] {spark_submit.py:571} INFO - 24/05/20 01:41:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:41:13.001+0000] {spark_submit.py:571} INFO - 24/05/20 01:41:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:41:23.010+0000] {spark_submit.py:571} INFO - 24/05/20 01:41:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:41:33.021+0000] {spark_submit.py:571} INFO - 24/05/20 01:41:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:41:43.030+0000] {spark_submit.py:571} INFO - 24/05/20 01:41:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:41:53.039+0000] {spark_submit.py:571} INFO - 24/05/20 01:41:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:42:03.037+0000] {spark_submit.py:571} INFO - 24/05/20 01:42:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:42:13.055+0000] {spark_submit.py:571} INFO - 24/05/20 01:42:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:42:23.065+0000] {spark_submit.py:571} INFO - 24/05/20 01:42:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:42:33.065+0000] {spark_submit.py:571} INFO - 24/05/20 01:42:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:42:43.075+0000] {spark_submit.py:571} INFO - 24/05/20 01:42:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:43:13.942+0000] {spark_submit.py:571} INFO - 24/05/20 01:43:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:43:23.959+0000] {spark_submit.py:571} INFO - 24/05/20 01:43:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:43:33.955+0000] {spark_submit.py:571} INFO - 24/05/20 01:43:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:43:43.963+0000] {spark_submit.py:571} INFO - 24/05/20 01:43:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:43:53.969+0000] {spark_submit.py:571} INFO - 24/05/20 01:43:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:44:03.978+0000] {spark_submit.py:571} INFO - 24/05/20 01:44:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:59:44.647+0000] {spark_submit.py:571} INFO - 24/05/20 01:59:44 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T01:59:54.655+0000] {spark_submit.py:571} INFO - 24/05/20 01:59:54 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:00:04.657+0000] {spark_submit.py:571} INFO - 24/05/20 02:00:04 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:15:42.406+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:15:47.866+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:47 WARN HeartbeatReceiver: Removing executor 0 with no recent heartbeats: 933262 ms exceeds timeout 120000 ms
[2024-05-20T02:15:47.967+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:47 INFO StandaloneSchedulerBackend: Requesting to kill executor(s) 0
[2024-05-20T02:15:47.994+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:47 INFO StandaloneSchedulerBackend: Actual list of executor(s) to be killed is 0
[2024-05-20T02:15:48.215+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240520000021-0007/0 is now LOST (worker lost: Not receiving heartbeat for 60 seconds)
[2024-05-20T02:15:48.256+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO StandaloneSchedulerBackend: Executor app-20240520000021-0007/0 removed: worker lost: Not receiving heartbeat for 60 seconds
[2024-05-20T02:15:48.260+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20240519000616-192.168.96.6-36477: Not receiving heartbeat for 60 seconds
[2024-05-20T02:15:48.261+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO StandaloneSchedulerBackend: Worker worker-20240519000616-192.168.96.6-36477 removed: Not receiving heartbeat for 60 seconds
[2024-05-20T02:15:48.281+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 ERROR TaskSchedulerImpl: Lost executor 0 on 192.168.96.6: worker lost: Not receiving heartbeat for 60 seconds
[2024-05-20T02:15:48.305+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO TaskSchedulerImpl: Handle removed worker worker-20240519000616-192.168.96.6-36477: Not receiving heartbeat for 60 seconds
[2024-05-20T02:15:48.311+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO DAGScheduler: Executor lost: 0 (epoch 0)
[2024-05-20T02:15:48.318+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO BlockManagerMaster: Removal of executor 0 requested
[2024-05-20T02:15:48.319+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asked to remove non-existent executor 0
[2024-05-20T02:15:48.324+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.
[2024-05-20T02:15:48.333+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(0, 192.168.96.6, 44029, None)
[2024-05-20T02:15:48.333+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.
[2024-05-20T02:15:48.334+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO BlockManagerMaster: Removed 0 successfully in removeExecutor
[2024-05-20T02:15:48.334+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO DAGScheduler: Shuffle files lost for host: 192.168.96.6 (epoch 0)
[2024-05-20T02:15:48.379+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO DAGScheduler: Shuffle files lost for worker worker-20240519000616-192.168.96.6-36477 on host 192.168.96.6
[2024-05-20T02:15:48.814+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240520000021-0007/1 on worker-20240519000616-192.168.96.6-36477 (192.168.96.6:36477) with 1 core(s)
[2024-05-20T02:15:48.819+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20240520000021-0007/1 on hostPort 192.168.96.6:36477 with 1 core(s), 1024.0 MiB RAM
[2024-05-20T02:15:49.372+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240520000021-0007/1 is now RUNNING
[2024-05-20T02:15:52.410+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:15:53.565+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:53 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.96.6:51416) with ID 1,  ResourceProfileId 0
[2024-05-20T02:15:53.636+0000] {spark_submit.py:571} INFO - 24/05/20 02:15:53 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.96.6:40393 with 434.4 MiB RAM, BlockManagerId(1, 192.168.96.6, 40393, None)
[2024-05-20T02:16:02.412+0000] {spark_submit.py:571} INFO - 24/05/20 02:16:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:16:12.426+0000] {spark_submit.py:571} INFO - 24/05/20 02:16:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:16:22.434+0000] {spark_submit.py:571} INFO - 24/05/20 02:16:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:16:32.449+0000] {spark_submit.py:571} INFO - 24/05/20 02:16:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:16:42.444+0000] {spark_submit.py:571} INFO - 24/05/20 02:16:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:16:52.445+0000] {spark_submit.py:571} INFO - 24/05/20 02:16:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:17:02.458+0000] {spark_submit.py:571} INFO - 24/05/20 02:17:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:17:12.458+0000] {spark_submit.py:571} INFO - 24/05/20 02:17:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:17:22.472+0000] {spark_submit.py:571} INFO - 24/05/20 02:17:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:17:32.479+0000] {spark_submit.py:571} INFO - 24/05/20 02:17:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:17:42.491+0000] {spark_submit.py:571} INFO - 24/05/20 02:17:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:17:52.496+0000] {spark_submit.py:571} INFO - 24/05/20 02:17:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:18:02.512+0000] {spark_submit.py:571} INFO - 24/05/20 02:18:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:18:12.512+0000] {spark_submit.py:571} INFO - 24/05/20 02:18:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:18:22.527+0000] {spark_submit.py:571} INFO - 24/05/20 02:18:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:18:32.534+0000] {spark_submit.py:571} INFO - 24/05/20 02:18:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:35:14.038+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:14 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:35:18.335+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240520000021-0007/1 is now LOST (worker lost: Not receiving heartbeat for 60 seconds)
[2024-05-20T02:35:18.340+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:18 INFO StandaloneSchedulerBackend: Executor app-20240520000021-0007/1 removed: worker lost: Not receiving heartbeat for 60 seconds
[2024-05-20T02:35:18.340+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:18 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20240519000616-192.168.96.6-36477: Not receiving heartbeat for 60 seconds
[2024-05-20T02:35:18.344+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:18 INFO StandaloneSchedulerBackend: Worker worker-20240519000616-192.168.96.6-36477 removed: Not receiving heartbeat for 60 seconds
[2024-05-20T02:35:18.345+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:18 ERROR TaskSchedulerImpl: Lost executor 1 on 192.168.96.6: worker lost: Not receiving heartbeat for 60 seconds
[2024-05-20T02:35:18.345+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:18 INFO TaskSchedulerImpl: Handle removed worker worker-20240519000616-192.168.96.6-36477: Not receiving heartbeat for 60 seconds
[2024-05-20T02:35:18.346+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:18 INFO DAGScheduler: Executor lost: 1 (epoch 2)
[2024-05-20T02:35:18.346+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:18 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
[2024-05-20T02:35:18.346+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:18 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 192.168.96.6, 40393, None)
[2024-05-20T02:35:18.347+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:18 INFO BlockManagerMaster: Removed 1 successfully in removeExecutor
[2024-05-20T02:35:18.347+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:18 INFO DAGScheduler: Shuffle files lost for host: 192.168.96.6 (epoch 2)
[2024-05-20T02:35:18.347+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:18 INFO DAGScheduler: Shuffle files lost for worker worker-20240519000616-192.168.96.6-36477 on host 192.168.96.6
[2024-05-20T02:35:20.066+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:20 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240520000021-0007/2 on worker-20240519000616-192.168.96.6-36477 (192.168.96.6:36477) with 1 core(s)
[2024-05-20T02:35:20.068+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:20 INFO StandaloneSchedulerBackend: Granted executor ID app-20240520000021-0007/2 on hostPort 192.168.96.6:36477 with 1 core(s), 1024.0 MiB RAM
[2024-05-20T02:35:20.768+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240520000021-0007/2 is now RUNNING
[2024-05-20T02:35:22.949+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:22 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.96.6:58818) with ID 2,  ResourceProfileId 0
[2024-05-20T02:35:23.008+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:23 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.96.6:46437 with 434.4 MiB RAM, BlockManagerId(2, 192.168.96.6, 46437, None)
[2024-05-20T02:35:24.032+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:24 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:35:34.042+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:34 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:35:44.046+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:44 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:35:54.052+0000] {spark_submit.py:571} INFO - 24/05/20 02:35:54 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:36:04.061+0000] {spark_submit.py:571} INFO - 24/05/20 02:36:04 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:36:14.073+0000] {spark_submit.py:571} INFO - 24/05/20 02:36:14 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:36:24.080+0000] {spark_submit.py:571} INFO - 24/05/20 02:36:24 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:36:34.096+0000] {spark_submit.py:571} INFO - 24/05/20 02:36:34 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:36:44.102+0000] {spark_submit.py:571} INFO - 24/05/20 02:36:44 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:36:54.107+0000] {spark_submit.py:571} INFO - 24/05/20 02:36:54 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:37:04.120+0000] {spark_submit.py:571} INFO - 24/05/20 02:37:04 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:53:19.478+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:19 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:53:23.787+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240520000021-0007/2 is now LOST (worker lost: Not receiving heartbeat for 60 seconds)
[2024-05-20T02:53:23.794+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:23 INFO StandaloneSchedulerBackend: Executor app-20240520000021-0007/2 removed: worker lost: Not receiving heartbeat for 60 seconds
[2024-05-20T02:53:23.795+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:23 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20240519000616-192.168.96.6-36477: Not receiving heartbeat for 60 seconds
[2024-05-20T02:53:23.795+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:23 INFO StandaloneSchedulerBackend: Worker worker-20240519000616-192.168.96.6-36477 removed: Not receiving heartbeat for 60 seconds
[2024-05-20T02:53:23.795+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:23 ERROR TaskSchedulerImpl: Lost executor 2 on 192.168.96.6: worker lost: Not receiving heartbeat for 60 seconds
[2024-05-20T02:53:23.796+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:23 INFO TaskSchedulerImpl: Handle removed worker worker-20240519000616-192.168.96.6-36477: Not receiving heartbeat for 60 seconds
[2024-05-20T02:53:23.796+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:23 INFO DAGScheduler: Executor lost: 2 (epoch 4)
[2024-05-20T02:53:23.796+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:23 INFO BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
[2024-05-20T02:53:23.797+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:23 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, 192.168.96.6, 46437, None)
[2024-05-20T02:53:23.797+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:23 INFO BlockManagerMaster: Removed 2 successfully in removeExecutor
[2024-05-20T02:53:23.797+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:23 INFO DAGScheduler: Shuffle files lost for host: 192.168.96.6 (epoch 4)
[2024-05-20T02:53:23.797+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:23 INFO DAGScheduler: Shuffle files lost for worker worker-20240519000616-192.168.96.6-36477 on host 192.168.96.6
[2024-05-20T02:53:25.410+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240520000021-0007/3 on worker-20240519000616-192.168.96.6-36477 (192.168.96.6:36477) with 1 core(s)
[2024-05-20T02:53:25.415+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20240520000021-0007/3 on hostPort 192.168.96.6:36477 with 1 core(s), 1024.0 MiB RAM
[2024-05-20T02:53:25.477+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240520000021-0007/3 is now RUNNING
[2024-05-20T02:53:27.180+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:27 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.96.6:36160) with ID 3,  ResourceProfileId 0
[2024-05-20T02:53:27.219+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:27 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.96.6:41669 with 434.4 MiB RAM, BlockManagerId(3, 192.168.96.6, 41669, None)
[2024-05-20T02:53:29.489+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:29 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:53:39.494+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:39 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:53:49.502+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:49 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:53:59.537+0000] {spark_submit.py:571} INFO - 24/05/20 02:53:59 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:54:09.506+0000] {spark_submit.py:571} INFO - 24/05/20 02:54:09 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:54:19.517+0000] {spark_submit.py:571} INFO - 24/05/20 02:54:19 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:54:29.527+0000] {spark_submit.py:571} INFO - 24/05/20 02:54:29 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:54:39.539+0000] {spark_submit.py:571} INFO - 24/05/20 02:54:39 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:54:49.552+0000] {spark_submit.py:571} INFO - 24/05/20 02:54:49 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:54:59.555+0000] {spark_submit.py:571} INFO - 24/05/20 02:54:59 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:55:09.563+0000] {spark_submit.py:571} INFO - 24/05/20 02:55:09 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:55:19.572+0000] {spark_submit.py:571} INFO - 24/05/20 02:55:19 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:55:29.579+0000] {spark_submit.py:571} INFO - 24/05/20 02:55:29 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:55:39.576+0000] {spark_submit.py:571} INFO - 24/05/20 02:55:39 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:56:07.612+0000] {spark_submit.py:571} INFO - 24/05/20 02:56:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:56:17.613+0000] {spark_submit.py:571} INFO - 24/05/20 02:56:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:56:27.624+0000] {spark_submit.py:571} INFO - 24/05/20 02:56:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:56:37.621+0000] {spark_submit.py:571} INFO - 24/05/20 02:56:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:56:47.636+0000] {spark_submit.py:571} INFO - 24/05/20 02:56:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:56:57.634+0000] {spark_submit.py:571} INFO - 24/05/20 02:56:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:57:07.640+0000] {spark_submit.py:571} INFO - 24/05/20 02:57:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:57:17.654+0000] {spark_submit.py:571} INFO - 24/05/20 02:57:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:57:27.656+0000] {spark_submit.py:571} INFO - 24/05/20 02:57:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:57:37.655+0000] {spark_submit.py:571} INFO - 24/05/20 02:57:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:57:47.658+0000] {spark_submit.py:571} INFO - 24/05/20 02:57:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:57:57.679+0000] {spark_submit.py:571} INFO - 24/05/20 02:57:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:58:16.694+0000] {spark_submit.py:571} INFO - 24/05/20 02:58:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:58:26.715+0000] {spark_submit.py:571} INFO - 24/05/20 02:58:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:58:36.705+0000] {spark_submit.py:571} INFO - 24/05/20 02:58:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:58:46.710+0000] {spark_submit.py:571} INFO - 24/05/20 02:58:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:58:56.724+0000] {spark_submit.py:571} INFO - 24/05/20 02:58:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:59:06.733+0000] {spark_submit.py:571} INFO - 24/05/20 02:59:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:59:16.746+0000] {spark_submit.py:571} INFO - 24/05/20 02:59:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:59:26.751+0000] {spark_submit.py:571} INFO - 24/05/20 02:59:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:59:36.759+0000] {spark_submit.py:571} INFO - 24/05/20 02:59:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:59:46.775+0000] {spark_submit.py:571} INFO - 24/05/20 02:59:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T02:59:56.781+0000] {spark_submit.py:571} INFO - 24/05/20 02:59:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:00:06.783+0000] {spark_submit.py:571} INFO - 24/05/20 03:00:06 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:01:13.588+0000] {spark_submit.py:571} INFO - 24/05/20 03:01:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:01:23.602+0000] {spark_submit.py:571} INFO - 24/05/20 03:01:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:01:33.611+0000] {spark_submit.py:571} INFO - 24/05/20 03:01:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:01:43.616+0000] {spark_submit.py:571} INFO - 24/05/20 03:01:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:01:53.625+0000] {spark_submit.py:571} INFO - 24/05/20 03:01:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:02:03.629+0000] {spark_submit.py:571} INFO - 24/05/20 03:02:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:02:13.641+0000] {spark_submit.py:571} INFO - 24/05/20 03:02:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:02:23.646+0000] {spark_submit.py:571} INFO - 24/05/20 03:02:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:02:33.646+0000] {spark_submit.py:571} INFO - 24/05/20 03:02:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:02:43.648+0000] {spark_submit.py:571} INFO - 24/05/20 03:02:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:02:53.656+0000] {spark_submit.py:571} INFO - 24/05/20 03:02:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:03:03.660+0000] {spark_submit.py:571} INFO - 24/05/20 03:03:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:03:13.669+0000] {spark_submit.py:571} INFO - 24/05/20 03:03:13 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:03:23.673+0000] {spark_submit.py:571} INFO - 24/05/20 03:03:23 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:03:33.677+0000] {spark_submit.py:571} INFO - 24/05/20 03:03:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:18:57.211+0000] {spark_submit.py:571} INFO - 24/05/20 03:18:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:19:01.902+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240520000021-0007/3 is now LOST (worker lost: Not receiving heartbeat for 60 seconds)
[2024-05-20T03:19:01.923+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:01 INFO StandaloneSchedulerBackend: Executor app-20240520000021-0007/3 removed: worker lost: Not receiving heartbeat for 60 seconds
[2024-05-20T03:19:01.925+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:01 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20240519000616-192.168.96.6-36477: Not receiving heartbeat for 60 seconds
[2024-05-20T03:19:01.925+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:01 INFO StandaloneSchedulerBackend: Worker worker-20240519000616-192.168.96.6-36477 removed: Not receiving heartbeat for 60 seconds
[2024-05-20T03:19:01.925+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:01 WARN HeartbeatReceiver: Removing executor 3 with no recent heartbeats: 919126 ms exceeds timeout 120000 ms
[2024-05-20T03:19:01.932+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:01 INFO StandaloneSchedulerBackend: Requesting to kill executor(s) 3
[2024-05-20T03:19:01.933+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:01 ERROR TaskSchedulerImpl: Lost executor 3 on 192.168.96.6: worker lost: Not receiving heartbeat for 60 seconds
[2024-05-20T03:19:01.949+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:01 INFO TaskSchedulerImpl: Handle removed worker worker-20240519000616-192.168.96.6-36477: Not receiving heartbeat for 60 seconds
[2024-05-20T03:19:01.961+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:01 INFO DAGScheduler: Executor lost: 3 (epoch 6)
[2024-05-20T03:19:01.972+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:01 INFO BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
[2024-05-20T03:19:01.978+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:01 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(3, 192.168.96.6, 41669, None)
[2024-05-20T03:19:01.978+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:01 INFO BlockManagerMaster: Removed 3 successfully in removeExecutor
[2024-05-20T03:19:01.980+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:01 INFO DAGScheduler: Shuffle files lost for host: 192.168.96.6 (epoch 6)
[2024-05-20T03:19:01.986+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:01 INFO DAGScheduler: Shuffle files lost for worker worker-20240519000616-192.168.96.6-36477 on host 192.168.96.6
[2024-05-20T03:19:02.082+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:02 WARN StandaloneSchedulerBackend: Executor to kill 3 does not exist!
[2024-05-20T03:19:02.084+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:02 INFO StandaloneSchedulerBackend: Actual list of executor(s) to be killed is
[2024-05-20T03:19:02.109+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:02 INFO BlockManagerMaster: Removal of executor 3 requested
[2024-05-20T03:19:02.110+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:02 INFO BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
[2024-05-20T03:19:02.111+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:02 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asked to remove non-existent executor 3
[2024-05-20T03:19:03.175+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240520000021-0007/4 on worker-20240519000616-192.168.96.6-36477 (192.168.96.6:36477) with 1 core(s)
[2024-05-20T03:19:03.192+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20240520000021-0007/4 on hostPort 192.168.96.6:36477 with 1 core(s), 1024.0 MiB RAM
[2024-05-20T03:19:03.378+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240520000021-0007/4 is now RUNNING
[2024-05-20T03:19:06.557+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:06 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.96.6:58958) with ID 4,  ResourceProfileId 0
[2024-05-20T03:19:06.626+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:06 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.96.6:40219 with 434.4 MiB RAM, BlockManagerId(4, 192.168.96.6, 40219, None)
[2024-05-20T03:19:07.209+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:19:17.235+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:19:27.256+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:19:37.247+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:19:47.252+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:19:57.262+0000] {spark_submit.py:571} INFO - 24/05/20 03:19:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:20:07.271+0000] {spark_submit.py:571} INFO - 24/05/20 03:20:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:20:17.286+0000] {spark_submit.py:571} INFO - 24/05/20 03:20:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:20:27.293+0000] {spark_submit.py:571} INFO - 24/05/20 03:20:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:20:37.306+0000] {spark_submit.py:571} INFO - 24/05/20 03:20:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:20:47.317+0000] {spark_submit.py:571} INFO - 24/05/20 03:20:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:20:57.326+0000] {spark_submit.py:571} INFO - 24/05/20 03:20:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:21:07.339+0000] {spark_submit.py:571} INFO - 24/05/20 03:21:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:21:17.360+0000] {spark_submit.py:571} INFO - 24/05/20 03:21:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:21:27.357+0000] {spark_submit.py:571} INFO - 24/05/20 03:21:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:21:37.356+0000] {spark_submit.py:571} INFO - 24/05/20 03:21:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:21:47.357+0000] {spark_submit.py:571} INFO - 24/05/20 03:21:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:21:57.374+0000] {spark_submit.py:571} INFO - 24/05/20 03:21:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:22:07.381+0000] {spark_submit.py:571} INFO - 24/05/20 03:22:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:22:17.379+0000] {spark_submit.py:571} INFO - 24/05/20 03:22:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:22:27.380+0000] {spark_submit.py:571} INFO - 24/05/20 03:22:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:22:37.381+0000] {spark_submit.py:571} INFO - 24/05/20 03:22:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:22:47.389+0000] {spark_submit.py:571} INFO - 24/05/20 03:22:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:22:57.399+0000] {spark_submit.py:571} INFO - 24/05/20 03:22:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:23:07.405+0000] {spark_submit.py:571} INFO - 24/05/20 03:23:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:23:17.410+0000] {spark_submit.py:571} INFO - 24/05/20 03:23:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:38:55.841+0000] {spark_submit.py:571} INFO - 24/05/20 03:38:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:39:05.869+0000] {spark_submit.py:571} INFO - 24/05/20 03:39:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:39:15.863+0000] {spark_submit.py:571} INFO - 24/05/20 03:39:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:39:25.870+0000] {spark_submit.py:571} INFO - 24/05/20 03:39:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:39:35.883+0000] {spark_submit.py:571} INFO - 24/05/20 03:39:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:39:45.883+0000] {spark_submit.py:571} INFO - 24/05/20 03:39:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:39:55.892+0000] {spark_submit.py:571} INFO - 24/05/20 03:39:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:40:05.918+0000] {spark_submit.py:571} INFO - 24/05/20 03:40:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:40:15.909+0000] {spark_submit.py:571} INFO - 24/05/20 03:40:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:40:25.910+0000] {spark_submit.py:571} INFO - 24/05/20 03:40:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:40:35.913+0000] {spark_submit.py:571} INFO - 24/05/20 03:40:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:40:45.921+0000] {spark_submit.py:571} INFO - 24/05/20 03:40:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:43:44.919+0000] {spark_submit.py:571} INFO - 24/05/20 03:43:44 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:43:54.923+0000] {spark_submit.py:571} INFO - 24/05/20 03:43:54 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:44:04.924+0000] {spark_submit.py:571} INFO - 24/05/20 03:44:04 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:44:14.926+0000] {spark_submit.py:571} INFO - 24/05/20 03:44:14 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:44:24.935+0000] {spark_submit.py:571} INFO - 24/05/20 03:44:24 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T03:44:34.940+0000] {spark_submit.py:571} INFO - 24/05/20 03:44:34 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T04:00:57.596+0000] {spark_submit.py:571} INFO - 24/05/20 04:00:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T04:01:07.613+0000] {spark_submit.py:571} INFO - 24/05/20 04:01:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2024-05-20T04:01:07.816+0000] {local_task_job_runner.py:310} WARNING - State of this instance has been externally set to up_for_retry. Terminating instance.
[2024-05-20T04:01:08.188+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-05-20T04:01:08.282+0000] {process_utils.py:132} INFO - Sending 15 to group 12941. PIDs of all processes in the group: [12942, 13013, 12941]
[2024-05-20T04:01:08.301+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 12941
[2024-05-20T04:01:08.354+0000] {taskinstance.py:2611} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-05-20T04:01:08.411+0000] {spark_submit.py:697} INFO - Sending kill signal to spark-submit
[2024-05-20T04:01:08.477+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-20T04:01:08.676+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=13013, status='terminated', started='00:00:10') (13013) terminated with exit code None
[2024-05-20T04:01:09.935+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 174, in execute
    self._hook.submit(self.application)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 490, in submit
    self._process_spark_submit_log(iter(self._submit_sp.stdout))  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 539, in _process_spark_submit_log
    for line in itr:
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2613, in signal_handler
    raise AirflowTaskTerminated("Task received SIGTERM signal")
airflow.exceptions.AirflowTaskTerminated: Task received SIGTERM signal
[2024-05-20T04:01:10.301+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=Redfin_Webscraping_ETL, task_id=Process_and_Send_Data_to_DB, run_id=scheduled__2024-05-19T00:00:00+00:00, execution_date=20240519T000000, start_date=20240520T000004, end_date=20240520T040110
[2024-05-20T04:01:10.467+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=12942, status='terminated', started='00:00:04') (12942) terminated with exit code None
[2024-05-20T04:01:10.470+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=12941, status='terminated', exitcode=2, started='00:00:04') (12941) terminated with exit code 2
